<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[tranning skill]]></title>
    <url>%2F2018%2F05%2F22%2Ftraining-skill%2F</url>
    <content type="text"><![CDATA[因为工作的关系，可能会需要做一些产品，技术和知识的培训计划或课程。通过一个从事于培训行业的朋友探讨后，她有些相当不错的建议，我根据她的建议做了一个简单的脑图(mind mapping)，方便以后做一个Check List。 Mind mapping源文件，可以通过百度脑图导入进行编辑。]]></content>
      <categories>
        <category>training</category>
      </categories>
      <tags>
        <tag>training</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dns tunneling]]></title>
    <url>%2F2018%2F05%2F14%2Fdns-tunnel%2F</url>
    <content type="text"><![CDATA[最经常碰到用户反馈，我们的反垃圾邮件网关总是向一些奇怪的地址做DNS查询请求，被防火墙检测出可能是DNS Tunnel的情况。从我们反垃圾邮件网关工作原理来说，确实会用到比较多的DNS查询来实现过滤的功能，但是该过滤功能跟DNS Tunnel是否有联系呢？ what is DNS tunnelDNS tunnel即DNS隧道。从名字上来看就是利用DNS查询过程建立起隧道，传输数据。 简单来说，当一个Client想要将数据发送给Server, Client会先把数据进行编码放在DNS payload中。例如Client可以发其域名为“MRZGS3TLEBWW64TFEBXXMYLMORUW4ZI.t.example.com”的A记录查询请求，然后Server返回“NVWW2IDPOZQWY5DJNZSQ.t.example.com”的CNAME的响应。这样数据以encode的方式发送给了Server，Server同时也将数据encode的方式响应了Client。这种通讯方式缺点是Server无法做到主动发起到客户的的连接，因为Client并没有监听DNS请求的服务，并且大多数情景是Client部署在防火墙后面。Server想要完成控制Client的通讯只有Client定期的监听发起到Serve的连接，然后Server通过响应数据包的控制Client通讯。 DNS Query先了解下DNS查询请求的过程。DNS协议默认使用的端口为53(TCP/UDP),一般在进行DNS查询的时候通常使用的是UDP协议,但是在主服务器向备服务器同步数据的时候通常使用的是TCP协议. 当你需要访问某个服务器时，需要知道其域名对应的服务器地址。 你需要使用Local/Public DNS服务器进行查询，向该服务器的53端口发送查询请求，比如需要查询abc.sample.com的服务器地址。 如果 Local/Public DNS服务器上如果没有abc.sample.com缓存记录，那么它将请求Root DNS服务器。 Root DNS会响应Local/Public DNS服务器sample.com的Name Server地址。 Local/Public DNS服务器再将请求转发到sample.com的服务器地址上。 sample.com的域名服务器上收到请求后，查看是abc.sample.com，如果它有这条A记录，那么就会返回abc.sample.com的地址给客户端。 Tunnel再了解一下tunnel，所谓 tunnel 就是把下一层（比如IPv4层）的包封装到上一层（比如 SSH，HTTP）或者同一层（比如IPv6层）的协议中进行传输，从而实现网络之间的穿透。发送端和接收端各有一个解析和封装这种包的程序或者内核模块，将数据通过其他比较常用的通讯协议进行传输。常见的Tunnel有基于SSH或HTTPS的tunnel方式，这两种方式既是常用的通讯协议，又是基于加密的安全方式通讯。另外我们VPN中用到的PPTP，L2TP都是tunnel的技术实现的，Tunnel的实现方式从网络传输模型的2层-7层都有解决方案。 DNS TunnelingDNS隧道技术简单来说就是将网络流量封装成DNS流量,以DNS查询的方式将数据传输到服务器上，服务器再通过DNS查询结果的方式响应客户。这里的流量封装通常由一个客户端来完成,Tunnel服务器将封装的DNS流量还原成正常的流量. 在复杂和较为安全的网络环境中,防火墙方对内部网络出去的流量一般有严格的控制。攻击者拿到内网机器的权限后如果想保持长久的对目标的控制并且不被发现,难度是比较大的,因为一些敏感操作(比如:执行命令、内部数据外传等)可能会触犯防火墙或者安全设备的规则,有时候拿下一台机器容易,但是长久控制就比较难. 如果你在互联网上有台定制的服务器。只要依靠 DNS 的数据包，就可以实现数据交换，那么对内网的渗透难度会小很多。从 DNS 协议上看，你只是在一次次的查询某个特定域名，并得到解析结果。但实际上，你在和外部通讯，你没有直接连到局域网外的机器，因为防火墙不会转发你的 IP 包出去。但局域网上的 DNS 服务器帮你做了中转。这就是 DNS Tunnel了。通过DNS Tunnel可以比较好的维持对目标的长期控制并且不易被发现.DNS隧道将所有流量进行封装,通过DNS请求传送出去,一般的安全设备和软件不会对DNS请求进行详细的检查,攻击者通过将payload加密隐藏在查询的hostname中进行发送,DNS服务器递归查询,最终到达攻击者的服务端解密,服务端也可以下发指令给客户端,客户端解密之后执行控制端的命令。 DNS tunnel implement toolsDNS tunnel实现的工具有很多，比如：OzymanDNS、tcp-over-dns、heyoka、iodine、dns2tcp Win7平台：dns2tcpLinux平台：iodine 这里只介绍基于Linux(CentOS)平台下iodine软件的实现方法. Tools域名：barracudachina.com主机Linux两台：CentOS 7Tunnel软件：iodine Operations[Server] # yum -y install iodine-server # iodined -f 10.0.0.1 -P SecretPassword tunnel.barracudachina.com Opened dns0 Setting IP of dns0 to 10.0.0.1 Setting MTU of dns0 to 1130 Opened IPv4 UDP socket Listening to dns for domain tunnel.barracudachina.com # ifconfig dns0: flags=4305&lt;UP,POINTOPOINT,RUNNING,NOARP,MULTICAST&gt; mtu 1130 inet 10.0.0.1 netmask 255.255.255.224 destination 10.0.0.1 unspec 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00 txqueuelen 500 (UNSPEC) RX packets 59 bytes 4956 (4.8 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 59 bytes 4956 (4.8 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 [Client] # yum -y install iodine-client # iodine -f -r 192.158.0.1 -P SecretPassword tunnel.barracudachina.com (Replace 192.168.0.1 with your server&#39;s ip address) Opened dns0 Opened IPv4 UDP socket Sending DNS queries for tunnel.barracudachina.com to 192.168.150.158 Autodetecting DNS query type (use -T to override). Using DNS type NULL queries Version ok, both using protocol v 0x00000502. You are user #0 Setting IP of dns0 to 10.0.0.2 Setting MTU of dns0 to 1130 Server tunnel IP is 10.0.0.1 Skipping raw mode Using EDNS0 extension Switching upstream to codec Base128 Server switched upstream to codec Base128 No alternative downstream codec available, using default (Raw) Switching to lazy mode for low-latency Server switched to lazy mode Autoprobing max downstream fragment size... (skip with -m fragsize) 768 ok.. 1152 ok.. ...1344 not ok.. ...1248 not ok.. ...1200 not ok.. 1176 ok.. 1188 ok.. will use 1188-2=1186 Setting downstream fragment size to max 1186... Connection setup complete, transmitting data. # ifconfig dns0: flags=4305&lt;UP,POINTOPOINT,RUNNING,NOARP,MULTICAST&gt; mtu 1130 inet 10.0.0.2 netmask 255.255.255.224 destination 10.0.0.2 unspec 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00 txqueuelen 500 (UNSPEC) RX packets 0 bytes 0 (0.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 0 bytes 0 (0.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 [DNS]在域名解析商的网站上，设置一条barracudachina.com的子域tunnel.barracudachina.com的NS记录： tunnel.barracudachina.com. 600 IN NS ns10.barracudachina.com. 另外，再设置ns10.barracudachina.com的A记录指向上面的[Server]地址 ns10.barracudachina.com. 600 IN A 101.231.149.69 [Test] # dig -t TXT z456.tunnel.barracudachina.com z456.tunnel.barracudachina.com. 300 IN TXT &quot;tpi0dknro&quot; # dig -t SRV z456.tunnel.barracudachina.com z456.tunnel.barracudachina.com. 300 IN SRV 10 10 5060 hpi0dknro.nx. # dig -t CNAME z456.tunnel.barracudachina.com z456.tunnel.barracudachina.com. 300 IN CNAME hpi0dknro.qf. 以上测试结果可以证明[Client]可以通过[DNS]递归查询实现与[Server]通信。 # ping 10.0.0.1 PING 10.0.0.1 (10.0.0.1) 56(84) bytes of data. 64 bytes from 10.0.0.1: icmp_seq=1 ttl=64 time=1.54 ms 64 bytes from 10.0.0.1: icmp_seq=2 ttl=64 time=1.13 ms 64 bytes from 10.0.0.1: icmp_seq=3 ttl=64 time=1.00 ms 该设置证明[Client]与[Server]之间的Tunnel已经建立成功。 PS:以上设置有任何疑问可以通过点击确认可能出现错误的原因。 Detecting DNS Tunneling因为DNS协议最初使用目的并不是用来传输数据的，其主要作用还是为了网站或邮件等重要服务。也正式这个原因，许多公司或组织往往会放行所有的DNS端口不做任何的监控。大部分企业将更多的资源专注于web或email的攻击，而忽略了通过DNS进行攻击的行为。例如最常见的情况为有些WIFI开启了http的portal进行身份验证后才能上网，因为这种情况下Client可以连接到DNS服务器查询，那么Client就可以通过DNS Tunnel获取免费的WIFI上网权限。也有攻击者通过建立DNS Tunnel获得远程控制主机权限，或者通过DNS Tunnel非法上传公司内部重要数据。 目前有很多工具可以实现DNS Tunnel，实现的方法也不近相同，有些工具通过在本地创建tap虚拟网卡并配置一个IP，服务器跟客户端建立了一个tunnel，所有tunnel数据封装在DNS请求和响应中传输。也有工具通过将数据直接以二进制数据的方式直接封装在DNS的请求和响应中。DNS请求类型也会不同，有的工具采用A记录方式，有的直接以Null的类型。要再说明一下的是数据在DNS payload中的编码（encode）。关于encode涉及的范围非常广如果想做更多的了解可以参考我之前的文档（encoding彻底理解字符编码,base64编码）。DNS Tunnel将encode后的数据封装在DNS的查询或请求中，encode格式也不太一样，像dns2tcp使用Base64编码，但是iodine又使用非标准的Base64编码格式… 基于以上的分析，许多DNS Tunneling工具都不会尝试隐匿，主要是因为实际情况下DNS不会被监控。目前有许多识别检测DNS Tunnel的技术，大致可以分为两类：基于数据包（Payload）分析和流量（traffic）分析 Payload Analysis数据包分析识别技术主要基于域名生成的一般规律[Domain Generation Algorithms (DGA)],数据编码生成的域名与DGA生成的域名相比不太正常，主要有这几类： Size of request and response DNS请求和响应的数据大小，通过这种在源和目的通信流量方法识别可疑的DNS Tunneling流量。既可以通过他们之间的通信数据统计量设置一个阀值（将DNS数据存储在MySQL中），也可以尝试检查DNS查询或相应的数据长度，因为DNS Tunneling总是尽可能的传输更多的数据。一个比较明显的判断依据是查看超过64-255字节的数据包，或者查看检查主机名请求长度超过52字节。 Entropy of hostnames通过请求hostname的熵检测DNS Tunnel。合法的DNS名通常可以通过字典匹配或者看上去有正常含义的，但是编码过主机名有更高的熵即使他们都是使用字符集。虽然DNS名有些类型的有列外表示一些特定的含义，例如CDN，但是这是参考条件之一。 Statistical Analysis检查包括的特殊字符在DNS名中是另外一种方法识别DNS Tunnel。合法的DNS名应该是比编码过的名字有更少的数字，有人提出通过基于在域名中数字的百分比，也可以通过在域名中通过最长的有意义的字符串等等。 Uncommon Record Types检查请求的记录类型为不是非常用的类型，例如请求类型为TXT记录。 Policy Violation如果设置一个策略要求所有DNS查询必须通过内部DNS Server，这种强制策略可以用于做检测DNS Tunnel，所有到Internet的DNS流量都可以被监控到，因为大部分DNS Tunnel工具都可以正常工作即使通过内网DNS Server转发的请求。 Specific Signatures有些研究者提供了特征码为一些特定的DNS Tunnel工具，通过DNS数据包头部的特殊字段识别。例如Snort Signature被开发出来用于检测NSTX DNS Tunnel。 alert udp $EXTERNAL_NET any -&gt; $HOME_NET 53 (msg:”Potential NSTX DNS Tunneling”; content:”|01 00|”; offset:2; within:4; content:”cT”; offset:12; depth:3; content:”|00 10 00 01|”; within:255; classtype:badunknown; sid:1000 2;) Traffic Analysis流量分析指的是通过查看一个时间段的多个请求/响应，这个数量和频率可以查看是否包括DNS Tunnel，这种技术方法主要包包括如下： Volume of DNS traffic per IP address一个比较直接的方法检查基于单个特定的Client IP的DNS流量，因为Tunnel的请求数据包大小一般限制在512字节，需要大量的请求包保持连接，并且如果Client建立了到Server的连接，那么会持续发送请求包。 Volume of DNS traffic per domain基于某个特定域的DNS流量分析是不是有特别大。DNS Tunnel需要设置一个域名来转发数据，所有转发到该DNS Tunnel的数据都会使用这个域。当然也有可能会使用多个域的情况，这样分到每个域的流量就小了。 Number of hostnames per domain统计一个给定的域名包括的hostname的数量，DNS Tunnel工具每次请求的hostname都不一样，这个比典型合法的域名要多很多，这是要很有效的流量分析方法。 Geographic location of DNS server将地理位置作为一个考虑因素也会被使用，很多DNS的流量都是没有实际商业用途，如果企业不是遍布全球的话，那么这个方法很实用。 Domain history域名历史也是可以用于提升识别DNS流量的方法，检查他们的A记录或者NS记录添加的情况，这个也常被用于检测一些恶意攻击行为，跟DNS Tunnel也相关。如果一个域名NS记录最近才被添加那么很有可能是用户DNS Tunnel的目的。 Orphan DNS requests孤立的DNS请求，以上的这些方法都是基于我们能看到的流量进行分析。另外一种途径是预测我们可以看到的情况。通常DNS请求是被其他的请求的附加行为，例如Web请求，这种预测可以很容易过滤出来。安全设备可以会使用DNS反向查询，反垃圾邮件通过DNS查询确定一个给定的IP地址是不是在黑名单中，终端安全产品使用包括一个FQDN hash码的DNS查询检查信誉库或可疑的文件。 Others查看NSDomain响应数量，流量可视化(Visualization)。 DNS[数据包结构]DNS Tunnel数据包样本(https://www.sans.org/reading-room/whitepapers/dns/detecting-dns-tunneling-34152)]]></content>
      <categories>
        <category>security</category>
        <category>network</category>
      </categories>
      <tags>
        <tag>security</tag>
        <tag>network</tag>
        <tag>dns</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ARP Protocol]]></title>
    <url>%2F2018%2F05%2F08%2Farp-protocol%2F</url>
    <content type="text"><![CDATA[ARP(Address Resolution Protocol)用于链路层地址发现的的协商协议。将已经分配了网络层的IPv4地址进行关联，该协议被定义在RFC 826标准中。ARP已经应用于多种不同的数据链路层的技术。例如IPv4，Chaosnet，DECnet和PUP。FDDI，X.25,Frame Relay，ATM等。 Operating scopeARP协议基于请求-响应链路层封装协议。数据包传输的边界为单个网络，不会再夸网段范围内传输。 ARP的该特性是基于因特网协议组的数据链路层工作模式。 Packet stratureARP使用简单消息格式包括地址解析的请求和响应包。包的大小基于上下层协议地址而决定。通常在IPv4网络协议下使用Hardware Address或virtual link address。消息报头定义了协议的类型和每个地址的大小。同事消息的头部Operation code定义了请求（1）和响应（2）。Payload中一共有4个地址，收发主机的Hardware Address和收发主机的IP地址。 下图中是一个标准的ARP数据包结构。如图所示，数据包包括48位的Sender Hardware Address（SHA）和Target Hardware Address（THA），以及32位的Sender/Target Protocol Address(SPA/TPA),因此协议包总共大小为28字节，ARP的以太帧类型ID为0x0806。 Hardware type (HTYPE)该字段定义了网络层协议类型。 例如，以太网为1 Protocol type (PTYPE)该字段定义数据包类型为ARP协议数据包，对于IPv4中对应的值为0x8000，改字段允许与以太帧其他类型共用。 Hardware length (HLEN)Hardware Address长度，以太网中地址长度为6字节。 Protocol length (PLEN)上层协议的地址长度（上层协议类型定义在PTYPE字段），在IPv4中大小为4字节。 Operation定义消息的操作类型。1表示请求，2表示响应。 Sender hardware address (SHA)发送者的物理地址，在ARP请求包中该字段主要是用于表示请求消息的发送地址。在ARP响应包中，该字段被用于指示请求者需要查找的地址。对于交换机来说对改字段不会做任何更改只是用于MAC地址的学习。 Sender protocol address (SPA)局域网中发送者的网络地址。 Target hardware address (THA)数据包接收者的物理地址，在ARP请求包中该字段为空。在ARP响应包中该字段被用于表示原始ARP请求者的物理地址。 Target protocol address (TPA)局域网中的目标接受者网络地址。 Example主机A的IP地址为192.168.1.1，MAC地址为0A-11-22-33-44-01； 主机B的IP地址为192.168.1.2，MAC地址为0A-11-22-33-44-02； 当主机A要与主机B通信时，地址解析协议可以将主机B的IP地址（192.168.1.2）解析成主机B的MAC地址，以下为工作流程： 第1步：根据主机A上的路由表内容，IP确定用于访问主机B的转发IP地址是192.168.1.2。然后A主机在自己的本地ARP缓存中检查主机B的匹配MAC地址。 第2步：如果主机A在ARP缓存中没有找到映射，它将询问192.168.1.2的硬件地址，从而将ARP请求帧广播到本地网络上的所有主机。源主机A的IP地址和MAC地址都包括在ARP请求中。本地网络上的每台主机都接收到ARP请求并且检查是否与自己的IP地址匹配。如果主机发现请求的IP地址与自己的IP地址不匹配，它将丢弃ARP请求。 第3步：主机B确定ARP请求中的IP地址与自己的IP地址匹配，则将主机A的IP地址和MAC地址映射添加到本地ARP缓存中。 第4步：主机B将包含其MAC地址的ARP回复消息直接发送回主机A。 第5步：当主机A收到从主机B发来的ARP回复消息时，会用主机B的IP和MAC地址映射更新ARP缓存。本机缓存是有生存期的，生存期结束后，将再次重复上面的过程。主机B的MAC地址一旦确定，主机A就能向主机B发送IP通信了。 ARP probeARP检测是一类ARP请求包，其结构为发送者的网络IP地址（SPA）为空，被用于网络中IPv4地址冲突发现，当一台主机需要使用一个IPv4地址时，可以广播ARP probe包确认该IP地址是否正在被使用。 ARP announcementsARP也当简单的消息宣告使用，可以用于更新主机IP地址与MAC地址的映射出现变更。这种ARP类型也叫做gratuitous ARP（GARP）消息。常见的情况是消息发送者通过广播自己的网络地址（SPA）到目标区域网络，并且包的Target Hardware Address(THA)为空。 GARP请求消息和响应消息都是标准类型。ARP宣告并不是为了是对方产生响应消息，而是更新目标主机的的ARP Cache表。其OPeration code既可以是请求类型也可以是响应类型，因为在ARP标准中规定者这种操作只是更新ARP表。许多操作系统在系统启动阶段就可以处理GARP消息。 这有助于及时更新网络中其他设备的ARP-IP的映射表。 [root@localhost ~]# arp -an ? (192.168.150.236) at 00:50:56:9d:1f:96 [ether] on eno16780032 ? (192.168.150.246) at 00:17:54:02:07:6e [ether] on eno16780032 ? (192.168.150.57) at 00:50:56:9d:6a:ee [ether] on eno16780032 ? (192.168.150.13) at 00:50:56:9d:46:1e [ether] on eno16780032 ? (192.168.150.247) at 00:17:54:02:c7:f6 [ether] on eno16780032 ? (192.168.150.3) at 00:25:90:7a:a3:63 [ether] on eno16780032 ? (192.168.150.158) at 00:50:56:b9:a7:52 [ether] on eno16780032 ? (192.168.150.155) at 00:50:56:9d:77:05 [ether] on eno16780032 ? (192.168.150.1) at 00:10:f3:5d:fa:38 [ether] on eno16780032 ? (192.168.150.245) at 74:4b:e9:01:03:6c [ether] on eno16780032 ? (192.168.150.156) at &lt;incomplete&gt; on eno16780032 GARP有时也会用于设备网口的负载均衡，在一个借口组中，宣告不同的MAC地址在端口组中能够接受所有的数据包。 ARP mediationARP中继用于解决二层地址需要夸越虚拟网络服务在复杂的网络环境中的问题。 Reverse ARP反向ARP解析被用于获得网络层地址（IP地址）通过二层数据链路地址。最开始用户Frame Relay和ATM网络。 主要是正常的网络层数据包转发时，通过ARP表查看IP-&gt;MAC决定转发的端口，但是有时数据报需要通过ARP表查看其MAC地址对应的网络地址，然后决定路由情况。 Proxy ARP（ARP spoofing）因为ARP协议并没有提供ARP响应的认证方法，所有ARP响应可以不是从真实的物理地址主机产生。ARP Proxy是一个主机响应ARP请求在真实的主机之前，常见是在拨号上网的情况下出现，另外对于ARP spoofing响应，利用ARP协议截获ARP请求包并对请求主机响应消息。黑客可以通过这种使用ARP spoofing这种方法扮演中间人的角色，获取传输过程的数据包。]]></content>
      <categories>
        <category>network</category>
      </categories>
      <tags>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web安全学习计划]]></title>
    <url>%2F2018%2F05%2F02%2Fweb-security-learning%2F</url>
    <content type="text"><![CDATA[通过本篇文章，您可以了解一个web安全从业人员所具备的大致知识面，同时我也制定了一个循序渐进的学习计划，用以帮您找准自己的定位，并可以自己制定适合自己的学习计划。 关键词以不求甚解的方式去看书，基于兴趣选择优先学习点，培养一个星期看完一本书的能力。 塔形的知识面在我看来，人类的知识都是具有阶梯式、层级式的特点，如果不了解下层的知识面，那么对于上层知识面的学习将会止于皮毛、浮于表面。对于web安全来说，我认为有5大块知识面是必须要掌握的，其层次关系如下图： 最下层的是os（操作系统）与db（数据库）。中间层是web，也是最重要的贯通上下的知识面。最上层的是安全攻防的知识和系统开发的知识，二者是纠缠在一起的上升螺旋。 建议的学习计划虽然知识面是层级式的，但是对于我们的学习来说，不应该抱有先把下层的知识学会、再学上层的知识。我推荐的学习态度是不求甚解。因为现今是知识大爆炸的时代，你不必为了一个问题而死转牛角尖，这会降低学习效率。正确的做法是快速获取主要的知识，然后进入下一阶段的学习，那些未明白的地方，总会在未来的某个时刻或触类旁通、或回头重学，到了那时，你对这些问题的掌握程度，将是异常的深刻。基于这种快速学习的方法，我给您的学习计划是这样的： 每个阶段所包含的学习内容和时间安排如下： 序号 阶段 花费时间 学习内容 1 os基础知识 4天 os基础操作，os文件系统，os权限系统，os用户管理，常用系统命令 2 web基础知识 2天 http协议，html&amp;js&amp;asp&amp;php&amp;jsp基础知识 3 安全攻防基础知识 7天 常见安全漏洞的典型利用，常用安全工具使用方法 4 db基础知识 1天 常见数据库简介（oracle、mysql、sqlite），常用sql语句 5 安全攻防进阶1 7天 渗透测试方法论，安全漏洞深入分析 6 web深入学习 15天 https协议，搭建个人web服务器，深入学习html&amp;php&amp;js 7 os深入学习 15天 程序进程线程，网络通信与端口，linux &amp; 深入学习oracle 8 系统开发基础知识 15天 学习python 9 安全攻防进阶2 15天+ 大量的安全实战，编写poc，学习安全工具的插件及高级利用 10 系统开发进阶1 15天+ 学习java 基础知识，java web开发 11 安全攻防进阶3 保持学习 根据自己的爱好，深入某个领域 12 系统开发进阶2 保持学习 根据安全攻防的需要进行学习 合计 96天+ 兴趣是学习的起点从上面的计划可以看出，对于枯燥无味的理论知识，刚开始只安排了2-3天的常识学习，马上就是动手操作性比较强的安全攻防基础，这可以极大的激起您学习的兴趣。这也是我推崇的学习方式，基于兴趣。当您对常见漏洞的利用方法了然于胸、并不断使用的时候，您肯定会产生很多疑惑，这时候再回过头去学习下层的理论知识，您会产生恍然大悟的畅快感，如同遮天的乌云忽然间就烟消云散了。 不要小瞧您的学习能力常听人说看一本书看了半年还没看完，一看到厚厚的书本就产生畏惧。其实您低估了不求甚解的学习效率，一个星期绝对可以看完一本书的。重要的是集中注意力，不要死转牛角尖，不要以为某个知识点没有明白就会错过了，我明确的告诉您，以后您还会再遇到那个知识点的，而那个时候稍加一想就会了。 自我定位与制定学习计划拿出纸和笔，把您自己已经会的知识画成一个个的圈，然后选择和您已有知识关联最大的知识面去优先学习，因为让零散的知识点尽量融合成一个整体是最有效率的。然后挑出您最感兴趣的知识面去次优先学习，最后参考我给您的计划，制定您个人的学习计划。并将其打印出来，然后按部就班的学习吧。]]></content>
      <categories>
        <category>security</category>
      </categories>
      <tags>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VMware security]]></title>
    <url>%2F2018%2F05%2F02%2FVMware-security%2F</url>
    <content type="text"><![CDATA[VMware虚拟化之后，典型的部署场景是这样的,对于下面的架构也会存在安全隐患 风险点一管理员可能没有修改带外管理接口的默认密码，或者设置了弱密码、企业内众所周知的通用密码。 1、首先，要有效管理和监控大量的物理服务器，管理员必须借助服务器提供的硬件管理接口和带外管理网络才能实现。例如，惠普的iLO接口，Dell和浪潮的IPMI接口，通过一个Web或Ssh界面，都能实现服务器硬件健康状态的监控、电源和开关、操作系统的安装、远程控制台等功能。 风险点二某些ESXi Server可能使用了弱密码，后来忘了修改。所有的ESXi Server使用相同的密码，也许写在了运维手册里。 2、其次，在虚拟主机操作系统层面，管理员需要管理大量的ESXi Server，可能需要借助外包或驻场才能完成系统的安装和初始设置，然后才能投入使用。关于弱密码实际是非常容易遇到的。 风险点三ESXi Server从来没有打过补丁，可能存在安全漏洞。 3、再次，因为每个虚拟主机上都跑着几十上百个的虚拟客户机，使得管理员轻易做不敢对虚拟主机任何变更操作。 风险点四不同管理员，操作权限的控制 4、再往更高的层走，到达vCenter这里拿到vCenter的管理权限，便可以统治成百上千的虚拟机了。而管理成百上千台的虚拟机，肯定不是一两个人可以做得来的。也许需要按照功能区域划分给不同的人去管理，日常的变更操作也许会交给驻场团队去进行。这便涉及到账号和权限的安全问题。 在主要的vCenter上，也许域控服务器就在其中，你现在可以对它进行一个热克隆操作，克隆一个离线的虚拟机，然后用vCenter的控制台去登录它，导出域数据库，通过vCenter拷贝到其它你控制的虚拟机中（例如，通过共享虚拟磁盘），再把克隆的机器删除。这个过程对于域控管理员来说，一点感知都没有，域控服务器自身也不会有任何异常的系统事件产生。 风险点五外部web portal的安全问题 5、让我们把目光投向更远的地方，落在那个称为“云”管理平台的系统上。实际上，它可能有其它的名字，叫“云”只是时髦一点。功能是类似的，就是通过Web门户，向内部IT用户提供便捷的通道去申请、维护和销毁虚拟机资源。这是一个很自然的需求，也有很多第三方厂家去做这样的平台。这样的平台也可能存在各种安全问题。 它的Web Portal账号是如何创建并管理的？它有多少个管理员权限的用户？它有没有默认密码？它的管理员账号日常是交给谁管理的？Web Portal有没有常见的Web漏洞，如SQL注入等。它后台的服务器包括数据库服务器有没有弱密码？它与vCenter、vSphere的联动是通过vCenter账号还是API Key来进行的？账号或API Key有没有加密存储？等等。 风险点六通过端口扫描获取虚拟机信息 6、补充：VMware产品的扫描和发现作为一个内部渗透人员，如果对企业环境中的VMware产品（包括vCenter、ESXi等）进行发现和识别呢？这个也是有技巧的。首先VMware产品有特定的服务端口，例如22,80,427,443,902,9875等。其次服务的banner信息，或者ssl证书信息中包含有VMware或vSphere等关键字。这样就可以使用zmap等扫描器+banner获取快速地发现网络中VMware产品。那么，如何确定vCenter与它所纳管的ESXi之间的逻辑关系呢？诀窍就是SLP协议与vpxa的API。SLP协议可以获取目标IP地址的VMware主机名、ESXi版本，例如： ~# /usr/bin/slptool &#39;unicastfindsrvs&#39; 10.1.12.135 &#39;service:VMwareInfrastructure&#39; service:VMwareInfrastructure://10.1.12.135,65535 ~# /usr/bin/slptool &#39;unicastfindattrs&#39; 10.1.12.135 &#39;service:VMwareInfrastructure&#39; (product=&quot;VMware ESXi 6.0.0build-1921158&quot;),(hardwareUuid=&quot;32393735-3733-4E43-4731-313954385050&quot;) 而vpxa API可以查询到ESXi所纳管的vCenter地址：URL为：url_fmt = ‘https://%s/vpxa‘ %(ip)两个SOAP请求如下： apixml1=’’’&lt;?xml version=”1.0”encoding=”UTF-8”?&gt; &lt;soapenv:Envelopexmlns:soapenc=&quot;http://schemas.xmlsoap.org/soap/encoding/&quot;xmlns:soapenv=&quot;http://schemas.xmlsoap.org/soap/envelope/&quot; xmlns:xsd=&quot; http://www.w3.org/2001/XMLSchema&quot;xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;&gt; &lt;soapenv:Body&gt;&lt;QueryVpxaStatusxmlns=&quot;urn:vpxa3&quot;&gt;&lt;_this type=&quot;VpxapiVpxaService&quot;&gt;vpxa&lt;/_this&gt;&lt;/QueryVpxaStatus&gt;&lt;/soapenv:Body&gt;&lt;/soapenv:Envelope&gt;&#39;&#39;&#39; apixml2=&#39;&#39;&#39;&lt;?xml version=&quot;1.0&quot;encoding=&quot;UTF-8&quot;?&gt; &lt;soapenv:Envelopexmlns:soapenc=&quot;http://schemas.xmlsoap.org/soap/encoding/&quot;xmlns:soapenv=&quot;http://schemas.xmlsoap.org/soap/envelope/&quot; xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema&quot;xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;&gt; &lt;soapenv:Body&gt;&lt;GetVpxaInfoxmlns=&quot;urn:vpxa3&quot;&gt;&lt;_thistype=&quot;VpxapiVpxaService&quot;&gt;vpxa&lt;/_this&gt;&lt;/GetVpxaInfo&gt;&lt;/soapenv:Body&gt;&lt;/soapenv:Envelope&gt;&#39;&#39;&#39;]]></content>
      <categories>
        <category>security</category>
        <category>vmware</category>
      </categories>
      <tags>
        <tag>security</tag>
        <tag>vmware</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Over The Great Wall]]></title>
    <url>%2F2018%2F04%2F28%2FOver-The-Great-Wall%2F</url>
    <content type="text"><![CDATA[科学上网是每个有志知识青年的必备技能，不仅要翻过围墙看外面的世界，还要从外面看围墙内的世界 ToolsClient + Server + (Broswer Proxy Extension + GFW List) 通过安装客户端(Client)与在墙外的服务器(Server)建立加密的连接.这种连接除了VPN外，还有基于Shadowsocks这种代理的解决方案，当然也有一些直接的墙外代理服务器，但是所有的数据都会被代理看到，不是一个很安全的方式。(Broswer Proxy Extention + GFW List)这个可选的方案。使科学上网变得更完美。 ClientShadowsocks Solution (free)Clients Download页面不一定能打开，但是可以根据图片找到对应的平台搜索提供的Client，Android或iOS建议在APP Store中找Outline，亲测有效。(有人反馈在国内的Android应用中找不到Outline，已经上传到我的Github，点击下载) https://shadowsocks.org/en/download/clients.html Client Confighttps://shadowsocks.org/en/config/quick-guide.html Config FileShadowsocks accepts JSON format configs like this: { &quot;server&quot;:&quot;my_server_ip&quot;, &quot;server_port&quot;:8388, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;barfoo!&quot;, &quot;timeout&quot;:600, &quot;method&quot;:&quot;chacha20-ietf-poly1305&quot; } Explanation of each field: server: your hostname or server IP (IPv4/IPv6). server_port: server port number. local_port: local port number. password: a password used to encrypt transfer. timeout: connections timeout in seconds. method: encryption method. VPN Solution (charge)通过VPN方案，选择一些付费的墙外VPN服务器，获取稳定，方便，快捷的科学上网方式。下面列出一些比较实用的VPN工具 ExpressVPN TunnelBear Windscribe Hotspot Shield Free Speedify ProtonVPN Free ServerFree Shadowsocks Server list我们应该感谢这个开放的互联网世界，总有一些热心青年不求任何回报的分享这些免费的资源。这些SS Server都已经配置好了分享出来的，只需要通过将安装的Client配置连接其中的一个服务器，成功后你就可以开始科学上网了。 通过下面第一个Node配置到客户端上翻墙后，打开第二链接获取更多节点。 定时更新node 中国免费科学上网解决方案(需要翻墙) 个人珍藏Singapore Node： ss://YWVzLTI1Ni1jZmI6d3d3LnNoYWRvd3NvY2tzcGguc3BhY2VAMTI4LjE5OS42Ni4xNzY6NDQz Private Shodowsocks Server Oversea如果自己有一定的动手能力，AWS在墙外的服务器可以部署一台EC2 Server，最重要的12个月最低配置Free~。 AWS EC2 SS Server 搭建教程 Broswer Proxy Extension有童鞋要问通过上面两个方法已经可以翻墙了，为什么还要这个浏览器插件。 情况是当使用上面工具后所有流量都通过翻墙到国外了，如果需要访问国内网站，通过翻墙代理后在连接国内服务器，会碰到特别慢和打不开的情况。 如果有一个开关，它可以自动根据你访问的域名选择走本地网络出去还是走VPN线路出去，需要时还可以手动选择，这个是不是很智能和实用！！！这就是下面要介绍的。 SwitchyOmega真的非常好用，个人一直在使用的一个Chrome代理插件。 FoxyProxy推荐FoxyProxy虽然没有SwitchyOmega好用，但是这个是不同浏览器支持的。 GFW List不多说，非常实用…而且持续更新 https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt 设置到上面的Proxy Extension中]]></content>
      <categories>
        <category>tool</category>
      </categories>
      <tags>
        <tag>tool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[base64编码]]></title>
    <url>%2F2018%2F04%2F24%2Fbase64%2F</url>
    <content type="text"><![CDATA[为什么当数据采用base64位编码传输时，传输的数据大小比真实文件大33%？这个在邮件传输时非常明显，经常碰到用户问为什么附件大小只有15M多一点，我服务器允许最大接收邮件时20M，但是邮件因为大小原因被拒绝。 为什么需要base64ASCII码一共规定了128个字符的编码,这128个符号,范围在[0,127]之间.其中,[0,31],及127, 33个属于不可打印的控制字符. 在电子邮件传输信息时,有些邮件网关会把[0,31]这些控制字符给悄悄清除.还有的早期程序,收到[128,255]之间的国际字符时,甚至会发生错误. 如何在不同邮件网关之间安全的传输控制字符,国际字符,甚至二进制文件?于是作为MIME多媒体电子邮件标准的一部分—base64被开发出来. 什么是base64Base64是网络上最常见的用于传输8Bit字节码的编码方式之一，Base64就是一种基于64个可打印字符来表示二进制数据的方法。可查看RFC2045～RFC2049，上面有MIME的详细规范。 在encoding文章中我提到每个国家读通过不同的方式在ASCII基础上扩展自己的文字编码。既然每个国家都有自己的编码表了，问题也就来了。现在都国际化了，我要用一个支持本国语言的编码系统，打开另一个编码系统编码的文本，会出现什么情况呢？这就是乱码了… 更为严重的是，随着互联网的出现，各个国家的电脑都需要通信，而通信的一种方式就是使用URL地址。每个国家都希望把这个地址写成自己国家的语言。但这会导致其他国家根本没法访问地址，因为打不出这个字符嘛。所以，人类迫切需要一种中间编码形式，既能够兼容ASCII码，又能够把任意一种编码形式转换成只使用可读字符就能表示的编码。 其中一种编码形式，就是Base64编码。 Base64编码，顾名思义，用64个可读字符进行编码。与Hex的16个字符（0-9，A-F）相比多了很多，但是比ASCII码又少了一倍，去除了不可读字符。标准Base64编码中，这些字符是： 数字（10个）：0,1,2,3,4,5,6,7,8,9 小写字母（26个）：a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z 大写字母（26个）：A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y,Z 加号以及斜杠（2个）：+，/ 有的时候，根据不同的需要，Base64还有很多变种。比如，如果浏览器地址中用“+”和“/”的话，浏览器会将其转换为%XX的形式，又多了一步。因此可以将“+”和“/”换成“-”和“_”。 这种编码形式长度也短，效率也高。这样一来，数据通信的时候，不管来的是什么语言，都转化成Base64后再发送和接收。要是别国地址什么的打不出来，就直接打Base64编码形式就好了。 原理对传输8Bit字节码的二进制数据进行处理，每3个字节一组，一共是3x8=24bit，划为4组，每组正好6个bit： 这样我们得到4个6bit数字作为索引，然后计算机是一个字节（8bit）存数，6bit不够，自动就补两个高位0了。 然后查下面表，获得相应的4个字符，就是base64编码后的字符串。 所以，Base64编码会把3字节的二进制数据编码为4字节的文本数据，长度增加33%，好处是编码后的文本数据可以在邮件正文、网页等直接显示。 如果要编码的二进制数据不是3的倍数，最后会剩下1个或2个字节怎么办？Base64用\x00字节在末尾补足后，再在编码的末尾加上1个或2个=号，表示补了多少字节，解码的时候，会自动去掉。 转码过程例子：将字符s13编码成base64 字符：s 1 3 ascii：115 49 51 2进制： 01110011 00110001 00110011 6位一组（4组）： **011100**110011**000100**110011 然后才有后面的： 011100 110011 000100 110011 高位补0： 00011100 00110011 00000100 00110011 得到： 28 51 4 51 查对下照表： c z E z base64在线编码和解码http://www.webatic.com/run/convert/base64.php 应用 用作HTTP表单和HTTP GET URL中的参数。 用作MIME格式邮件SMTP传输 用Base64来保密电子邮件密码 代码实现JavaScriptif (!Shotgun) var Shotgun = {}; if (!Shotgun.Js) Shotgun.Js = {}; Shotgun.Js.Base64 = { _table: [ &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;, &#39;G&#39;, &#39;H&#39;, &#39;I&#39;, &#39;J&#39;, &#39;K&#39;, &#39;L&#39;, &#39;M&#39;, &#39;N&#39;, &#39;O&#39;, &#39;P&#39;, &#39;Q&#39;, &#39;R&#39;, &#39;S&#39;, &#39;T&#39;, &#39;U&#39;, &#39;V&#39;, &#39;W&#39;, &#39;X&#39;, &#39;Y&#39;, &#39;Z&#39;, &#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;, &#39;g&#39;, &#39;h&#39;, &#39;i&#39;, &#39;j&#39;, &#39;k&#39;, &#39;l&#39;, &#39;m&#39;, &#39;n&#39;, &#39;o&#39;, &#39;p&#39;, &#39;q&#39;, &#39;r&#39;, &#39;s&#39;, &#39;t&#39;, &#39;u&#39;, &#39;v&#39;, &#39;w&#39;, &#39;x&#39;, &#39;y&#39;, &#39;z&#39;, &#39;0&#39;, &#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;, &#39;5&#39;, &#39;6&#39;, &#39;7&#39;, &#39;8&#39;, &#39;9&#39;, &#39;+&#39;, &#39;/&#39; ], encode: function (bin) { var codes = []; var un = 0; un = bin.length % 3; if (un == 1) bin.push(0, 0); else if (un == 2) bin.push(0); for (var i = 2; i &lt; bin.length; i += 3) { var c = bin[i - 2] &lt;&lt; 16; c |= bin[i - 1] &lt;&lt; 8; c |= bin[i]; codes.push(this._table[c &gt;&gt; 18 &amp; 0x3f]); codes.push(this._table[c &gt;&gt; 12 &amp; 0x3f]); codes.push(this._table[c &gt;&gt; 6 &amp; 0x3f]); codes.push(this._table[c &amp; 0x3f]); } if (un &gt;= 1) { codes[codes.length - 1] = &quot;=&quot;; bin.pop(); } if (un == 1) { codes[codes.length - 2] = &quot;=&quot;; bin.pop(); } return codes.join(&quot;&quot;); }, decode: function (base64Str) { var i = 0; var bin = []; var x = 0, code = 0, eq = 0; while (i &lt; base64Str.length) { var c = base64Str.charAt(i++); var idx = this._table.indexOf(c); if (idx == -1) { switch (c) { case &#39;=&#39;: idx = 0; eq++; break; case &#39; &#39;: case &#39;\n&#39;: case &quot;\r&quot;: case &#39;\t&#39;: continue; default: throw { &quot;message&quot;: &quot;\u0062\u0061\u0073\u0065\u0036\u0034\u002E\u0074\u0068\u0065\u002D\u0078\u002E\u0063\u006E\u0020\u0045\u0072\u0072\u006F\u0072\u003A\u65E0\u6548\u7F16\u7801\uFF1A&quot; + c }; } } if (eq &gt; 0 &amp;&amp; idx != 0) throw { &quot;message&quot;: &quot;\u0062\u0061\u0073\u0065\u0036\u0034\u002E\u0074\u0068\u0065\u002D\u0078\u002E\u0063\u006E\u0020\u0045\u0072\u0072\u006F\u0072\u003A\u7F16\u7801\u683C\u5F0F\u9519\u8BEF\uFF01&quot; }; code = code &lt;&lt; 6 | idx; if (++x != 4) continue; bin.push(code &gt;&gt; 16); bin.push(code &gt;&gt; 8 &amp; 0xff); bin.push(code &amp; 0xff) code = x = 0; } if (code != 0) throw { &quot;message&quot;: &quot;\u0062\u0061\u0073\u0065\u0036\u0034\u002E\u0074\u0068\u0065\u002D\u0078\u002E\u0063\u006E\u0020\u0045\u0072\u0072\u006F\u0072\u003A\u7F16\u7801\u6570\u636E\u957F\u5EA6\u9519\u8BEF&quot; }; if (eq == 1) bin.pop(); else if (eq == 2) { bin.pop(); bin.pop(); } else if (eq &gt; 2) throw { &quot;message&quot;: &quot;\u0062\u0061\u0073\u0065\u0036\u0034\u002E\u0074\u0068\u0065\u002D\u0078\u002E\u0063\u006E\u0020\u0045\u0072\u0072\u006F\u0072\u003A\u7F16\u7801\u683C\u5F0F\u9519\u8BEF\uFF01&quot; }; return bin; } }; BASHbase64Table=(A B C D E F G H I J K L M N O P Q R S T U V W X Y Z a b c d e f g h i j k l m n o p q r s t u v w x y z 0 1 2 3 4 5 6 7 8 9 + /); function str2binary() { idx=0; for((i=0; i&lt;${#str}; i++)); do dividend=$(printf &quot;%d&quot; &quot;&#39;${str:i:1}&quot;); for((j=0;j&lt;8;j++)); do let idx=8*i+7-j; let bin[$idx]=$dividend%2; dividend=$dividend/2; done; done; let idx=${#str}*8; for((i=0; i&lt;appendEqualCnt*2; i++)); do let bin[$idx]=0; let idx++; done; } function calcBase64() { for((i=0; i&lt;${#bin[*]}/6; i++)); do sum=0; for((j=0; j&lt;6; j++)); do let idx=i*6+j; let n=6-1-j; let sum=sum+${bin[$idx]}*2**n; done; echo -n ${base64Table[$sum]}; done } declare -a bin function base64Encode() { read -p &quot;please enter ASCII string:&quot; str; let appendZero=${#str}*8%6; let bits=${#str}*8; appendEqualCnt=0; if [[ $appendZero -ne 0 ]]; then let appendEqualCnt=(6-$appendZero)/2; fi str2binary; calcBase64; if [[ $appendEqualCnt -eq 2 ]]; then echo -n &quot;==&quot;; elif [[ $appendEqualCnt -eq 1 ]]; then echo -n &quot;=&quot;; fi echo; } Javaimport java.util.Base64; 对于标准的Base64： 加密为字符串使用Base64.getEncoder().encodeToString(); 加密为字节数组使用Base64.getEncoder().encode(); 解密使用Base64.getDecoder().decode(); 对于URL安全或MIME的Base64，只需将上述getEncoder()getDecoder()更换为getUrlEncoder()getUrlDecoder() 或getMimeEncoder()和getMimeDecoder()即可。]]></content>
      <categories>
        <category>encode</category>
      </categories>
      <tags>
        <tag>encode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[encoding彻底理解字符编码]]></title>
    <url>%2F2018%2F04%2F23%2Fencoding%2F</url>
    <content type="text"><![CDATA[为什么要进行编码，这些编码的关系如何，如ASCII，IOS-8859-1，GB2312，GBK，Unicode之间的关系，笔者想要彻底理解字符编码背后的故事，遂进行了探索，具体笔记如下。如能读完本篇文章，我相信会解开很多疑惑。 字符编码为何需要编码？我们知道，所有的信息最终都表示为一个二进制的字符串，每一个二进制位（bit）有0和1两种状态。当我们需要把字符’A’存入计算机时，应该对应哪种状态呢，存储时，我们可以将字符’A’用01000010（这个随便编的）二进制字符串表示，存入计算机；读取时，再将01000010还原成字符’A’。那么问题来了，存储时，字符’A’应该对应哪一串二进制数呢，是01000010？或者是10000000 11110101？说白了，就是需要一个规则。这个规则可以将字符映射到唯一一种状态(二进制字符串)，这就是编码。而最早出现的编码规则就是ASCII编码，在ASCII编码规则中，字符’A’既不对应01000010，也不对应1000 0000 11110101，而是对应01000001（不要问为什么，这是规则）。 ASCII这套编码规则是由美国定制，一共规定了128个字符的编码，比如空格”SPACE”是32（十进制）（二进制00100000），大写的字母A是65（二进制01000001）。这128个符号（包括 32个不能打印出来的控制符号），只占用了一个字节（8 bit）的后面7位，最前面的1位统一规定为0。总共才有128个字符编码，一个字节都没有用完，这好像似乎有点太少了。于是乎，就开始压榨最高位，对其为1时也进行编码，利用最高位进行编码的方式就称为非ASCII编码，如ISO-8859-1编码。 ISO-8859-1这套编码规则由ISO组织制定。是在 ASCII 码基础上又制定了一些标准用来扩展ASCII编码，即 00000000（0） ~ 01111111（127） 与ASCII的编码一样，对 10000000（128） ~ 11111111（255）这一段进行了编码，如将字符§编码成 10100111（167）。ISO-8859-1编码也是单字节编码，最多能够表示256个字符。Latin1是ISO-8859-1的别名，有些环境下写作Latin-1。但是，即使能够表示256个字符，对中文而言，还是太少了，一个字节肯定不够，必须用多个字节表示。但是，由于是单字节编码，和计算机最基础的表示单位一致，所以很多时候，仍旧使用 ISO8859-1编码来表示。而且在很多协议上，默认使用该编码。比如，虽然”中文”两个字不存在ISO8859-1编码，以GB2312编码为例，应该是D6D0 CEC4两个字符，使用ISO8859-1编码的时候则将它拆开为4个字节来表示：D6D0 CEC4（事实上，在进行存储的时候，也是以字节为单位进行处理）。而如果是UTF编码，则是6个字节e4 b8 ad e6 96 87。很明显，这种表示方法还需要以另一种编码为基础才能正确显示。而常见的中文编码方式有GB2312、BIG5、GBK。 GB2312GB2312其对所收录字符进行了”分区”处理，共94个区，区从1（十进制）开始，一直到94（十进制），每区含有94个位，位从1（十进制）开始，一直到94（十进制），共8836（94 * 94）个码位，这种表示方式也称为区位码，GB2312是双字节编码，其中高字节表示区，低字节表示位。各区具体说明如下： 01-09区收录除汉字外的682个字符，有164个空位（9 * 94 - 682）。 10-15区为空白区，没有使用。 16-55区收录3755个一级汉字（简体），按拼音排序。 56-87区收录3008个二级汉字（简体），按部首/笔画排序。 88-94区为空白区，没有使用。 那么根据区位码如何算出GBK2312编码呢？区位码的表示范围为0101 - 9494（包含了空的区位码）。点击这里，查看中GB2312编码区位码。之后只需要按照如下规则进行转化即可。 1. 将区（十进制）转化为十六进制。 2. 将转化的十六进制加上A0，得到GB2312编码的高字节。 3. 将位（十进制）转化为十六进制。 4. 将转化的十六进制加上A0，得到GB2312编码的低字节。 5. 组合区和位，区在高字节，位在低字节。 6. 得到GB2312编码。 具体的流程图如下： 例如：’李’字的区位码为3278（表示在32区，78位）。1. 将32（区）转化为十六进制为20。2. 加上A0为C0。3. 将78（位）转化为十六进制为4E。4. 加上A0为EE。5. 组合区和位，为C0EE。6. 得到GB2312编码，即’李’字的GB2312编码为C0EE。 GB2312用两个字节编码，采用分区编码，总共编码的中文个数为6763（3755 + 3008）。这些汉字只是最常用的汉字，已经覆盖中国大陆99.75%的使用频率。但是，还有一些汉字在GB2312中没有被编码，如’镕’字，在GB2312中就没有被编码，这样就导致了问题，随之就出现了主流的GBK编码。在讲解GBK编码之前，我们另外讲解一下BIG5编码。 BIG5BIG5采用双字节编码，使用两个字节来表示一个字符。高位字节使用了0x81-0xFE，低位字节使用了0x40-0x7E，及0xA1-0xFE。该编码是繁体中文字符集编码标准，共收录13060个中文字，其中有二字为重复编码，即“兀、兀”（A461及C94A)和“嗀、嗀”(DCD1及DDFC)。具体的分区如下： 8140-A0FE 保留给使用者自定义字符（造字区） A140-A3BF 标点符号、希腊字母及特殊符号。其中在A259-A261，收录了度量衡单位用字：兙兛兞兝兡兣嗧瓩糎。 A3C0-A3FE 保留。此区没有开放作造字区用。 A440-C67E 常用汉字，先按笔划再按部首排序。 C6A1-F9DC 其它汉字。 F9DD-F9FE 制表符。 点击这里，查看BIG5编码。注意，BIG5编码与GBK编码没有什么关系。 GBKGBK编码扩展了GB2312，完全兼容GB2312编码（如’李’字的GBK、GB2312编码均为C0EE），但其不兼容BIG5编码（’長’字的BIG5编码为AAF8，GBK编码为E94C，’李’字的BIG5编码为A7F5 不等于C0EE），即如果使用GB2312编码，使用GBK解码是完全正常的，但是如果使用BIG5编码，使用GBK解码，会出现乱码。相比于GB2312编码，GBK编码了更多汉字，如’镕’字。GBK编码依然采用双字节编码方案，其编码范围：8140－FEFE，剔除xx7F码位，共23940个码位。能表示 21003 个汉字。点击这里，查看GBK编码。点击这里，可以查询中文的其他编码。在GBK之后又出现了GB18030编码，但是没有形成主流，故不做介绍，至此，中文编码的问题已经讲解完成。那么问题又来了，大陆网民与在海峡两岸网民交流时，若都使用GBK编码，则没有问题，若一方使用GBK编码，一方使用BIG5编码，那么就会出现乱码问题，这是在海峡两岸网民交流，如果漂洋过海进行交流呢？那就更容易出现乱码问题，这时候我们可能想，要是有一套全世界都通用的编码就好了，不要担心，这样的编码确实是存在的，那就是Unicode。 Unicode有两个独立的, 创立单一字符集的尝试. 一个是国际标准化组织(ISO)的 ISO 10646 项目, 另一个是由多语言软件制造商组成的协会组织的 Unicode 项目. 在1991年前后, 两个项目的参与者都认识到, 世界不需要两个不同的单一字符集. 它们合并双方的工作成果, 并为创立一个单一编码表而协同工作. 两个项目仍都存在并独立地公布各自的标准, 但 Unicode 协会和 ISO/IEC JTC1/SC2 都同意保持 Unicode 和 ISO 10646 标准的码表兼容, 并紧密地共同调整任何未来的扩展。 Unicode是指一张表，里面包含了可能出现的所有字符，每个字符对应一个数字，这个数字称为码点(Code Point)，如字符’H’的码点为72（十进制），字符’李’的码点为26446（十进制）。Unicode表包含了1114112个码点，即从000000（十六进制） - 10FFFF（十六进制）。地球上所有字符都可以在Unicode表中找到对应的唯一码点。点击这里，查询字符对应的码点。Unicode将码空间划分为17个平面，从00 - 10（十六进制，最高两位），即从0 - 16（十进制），每个平面有65536个码点（2^16），其中最重要的是第一个Unicode平面(码位从0000 - FFFF)，包含了最常用的字符，该平面被称为基本多语言平面（Basic Multilingual Plane），缩写为BMP，其他平面称为辅助平面(Supplementary Planes)，在基本多文种平面內， 从D800到DFFF之间的码位区段是永久保留不映射到字符的， 因此UTF-16编码巧妙的利用了这保留下来的码位来对辅助平面内的字符进行编码，这点后面进行讲解。Unicode只是一个符号集，只规定的字符所对应的码点，并没有指定如何存储，如何进行存储出现了不同的编码方案，关于Unicode编码方案主要有两条主线：UCS和UTF。UTF主线由Unicode Consortium进行维护管理，UCS主线由ISO/IEC进行维护管理。 UCSUCS全称为”Universal Character Set”，在UCS中主要有UCS-2和UCS-4。 1. UCS-2 UCS-2是定长字节的，固定使用2个字节进行编码，从0000（十六进制）- FFFF（十六进制）的码位范围，对应第一个Unicode平面。采用BOM(Byte Order Mark)机制，该机制作用如下：1. 确定字节流采用的是大端序还是小端序。2. 确定字节流的Unicode编码方案。 2. UCS-4 UCS-4是定长字节的，固定使用4个字节进行编码。也采用了BOM机制。 UTFUTF全称为”Unicode Transformation Format”，在UTF中主要有UTF-8，UTF-16和UTF-32。 1. UTF-8 UTF-8是一种变长编码方式，使用1-4个字节进行编码。UTF-8完全兼容ASCII，对于ASCII中的字符，UTF-8采用的编码值跟ASCII完全一致。UTF-8是Unicode一种具体的编码实现。UTF-8是在互联网上使用最广的一种Unicode的编码规则，因为这种编码有利于节约网络流量（因为变长编码，而非统一长度编码）。关于Unicode码点如何转化为UTF-8编码，可以参照如下规则： ① 对于单字节的符号，字节的第一位设为0，后面7位为这个符号的unicode码。因此对于英语字母，UTF-8编码和ASCII码是相同的。 ② 对于n字节的符号（n&gt;1），第一个字节的前n位都设为1，第n+1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的unicode码。 总结的编码规则如下： Unicode符号范围 | UTF-8编码方式 (十六进制) (十进制) | （二进制） ---------------------------------------------------------------------------------------------------- 0000 0000-0000 007F (0-127) | 0xxxxxxx 0000 0080-0000 07FF (128-2047) | 110xxxxx 10xxxxxx 0000 0800-0000 FFFF (2048-65535) | 1110xxxx 10xxxxxx 10xxxxxx 0001 0000-0010 FFFF (65536-1114111) | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx 说明：字符’A’的Unicode码点为65（十进制），根据上表，在第一行范围，则字符’A’的UTF-8编码为01000001，中文字符’李’的Unicode码点为26446（十进制），二进制为01100111 01001110，十六进制为674E。根据上表，在第三行范围，则将’李’二进制代码从低位到高位依次填入x中，不足的填入0。得到UTF-8编码为11100110 10011101 10001110，即E69D8E（十六进制）。 由上述编码规则可知，0000 0000 - 0000 FFFF（第一行到第三行）为Unicode第一个平面（基本多语言平面），而0001 0000 - 10 FFFF（第四行）为Unicode其他平面（辅助平面）。在基本多语言平面对应了绝大多数常用的字符。对于大于65535（十进制）的码点，即在辅助平面上的码点，需要使用4个字节来进行UTF-8编码。 2. UTF-16 UTF-8是不定长的编码，使用1、2、3、4个字节编码，而UTF-16则只使用2或4个字节编码。UTF-16也是Unicode一种具体的编码实现。关于Unicode如何转化为UTf-16编码规则如下 ① 若Unicode码点在第一平面（BPM）中，则使用2个字节进行编码。 ② 若Unicode码点在其他平面（辅助平面），则使用4个字节进行编码。 关于辅助平面的码点编码更详细解析如下：辅助平面码点被编码为一对16比特（四个字节）长的码元, 称之为代理对(surrogate pair), 第一部分称为高位代理(high surrogate)或前导代理(lead surrogates)，码位范围为：D800-DBFF. 第二部分称为低位代理(low surrogate)或后尾代理(trail surrogates)， 码位范围为：DC00-DFFF。注意，高位代理的码位从D800到DBFF，而低位代理的码位从DC00到DFFF，总共恰好为D800-DFFF，这部分码点在第一平面内是保留的，不映射到任何字符，所以UTF-16编码巧妙的利用了这点来进行码点在辅助平面内的4字节编码。 说明：字符’A’的Unicode码点为65（十进制），十六进制表示为41，在第一平面。根据规则，UTF-16采用2个字节进行编码。那么问题又来了，知道了采用两个字节编码，并且我们也知道计算机是以字节为单位进行存储，这两个字节应该表示为00 41(十六进制)？或者是41 00（十六进制）呢？这就引出了一个问题，需要用到之前提及的BOM机制来解决。 表示为00 41意味着采用了大端序（Big endian），而表示为41 00意味着采用了小端序。那么计算机如何知道存储的字符信息采用了大端序还是小端虚呢？这就需要加入一些控制信息，具体是采用大端序，则在文件前加入FE FF，采用小端序，则在文件前加入FF FE。这样，当计算开始读取时发现前两个字节为FE FF，就表示之后的信息采用的是小端序，反之，则是大端序。 字符 （无法显示，只能截图显示），其Unicode码点为65902（十进制），十六进制为1016E，很显然，已经超出了第一平面（BMP）所能表示的范围。其在辅助平面内，根据规则，UTF-16采用4个字节进行编码。然而其编码不是简单扩展为4个字节（00 01 01 6E），而是采用如下规则进行计算。 ① 使用Unicode码位减去100000（十六进制），得到的值扩展20位（因为Unicode最大为10 FF FF（十六进制），减去1 00 00（十六进制）后，得到的结果最大为0FFF FF（十六进制），即为20位，不足20位的，在高位加一个0，扩展至20位即可）。 ② 将步骤一得到的20位，按照高十位和低十位进行分割。 ③ 将步骤二的高十位扩展至2个字节，再加上D800（十六进制），得到高位代理或前导代理。取值范围是D800 - 0xDBFF。 ④ 将步骤二的低十位扩展至2个字节，再加上DC00（十六进制），得到低位代理或后尾代理。取值范围是DC00 - 0xDFFF。 Unicode转UTF-16规则流程图如下： 按照这个规则，我们计算字符的UTF-16编码，我们知道其码点为1016E，减去10000得到016E，扩展至0016E，进行分割，得到高十位为00 0000 0000，十六进制为0000，加上D800为D800；得到低十位为01 0110 1110，十六进制为016E，加上DC00为DD6E；综合得到D8 00 DD 6E。即UTF-16编码为D8 00 DD 6E（也可为D8 0 DD 6E）。 而对于UTF-32是使用4个字节表示，也采用BOM机制，可以类比UTF-16，这里不再额外介绍。 字符编码区别UCS-2 与 UTF-16区别从上面的分析知道，UCS-2采用的两个字节进行编码。在0000到FFFF的码位范围内，它和UTF-16基本一致，为什么说基本一致，因为在UTF-16中从U+D800到U+DFFF的码位不对应于任何字符，而在使用UCS-2的时代，U+D800到U+DFFF内的值被占用。 UCS-2只能表示BMP内的码点（只采用2个字节），而UTF-16可以表示辅助平面内的码点（采用4个字节）。 我们可以抽象的认为UTF-16可看成是UCS-2的父集。在没有辅助平面字符（surrogate code points）前，UTF-16与UCS-2所指的意思基本一致。但当引入辅助平面字符后，想要表示辅助平面字符时，就只能用UTF-16编码了。 UCS -4与 UTF-16的区别在BMP上，UTF-16采用2个字节表示，而在辅助平面上，UTF-16采用的是4个字节表示。对于UCS-4，不管在哪个平面都采用的是四个字节表示。 为什么UTF-8编码不需要BOM机制因为在UTF-8编码中，其自身已经带了控制信息，如1110xxxx 10xxxxxx 10xxxxxx 10xxxxxx，其中1110就起到了控制作用，所以不需要额外的BOM机制。 总结如果读者有耐心看到这里，我相信对于字符编码这一块已经就已经没有什么疑问了。写到这里，就完成了主流编码的探索，探索的过程确实是不容易，最后弄清楚了，感觉相当的快乐。 参考链接： https://www.cnblogs.com/leesf456/p/5317574.html http://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html#comment-text http://www.joelonsoftware.com/articles/Unicode.html http://blog.csdn.net/xys_777/article/details/5773763 http://www.zhihu.com/question/19817672 http://demon.tw/programming/utf-16-ucs-2.html http://blog.csdn.net/dslztx/article/details/48830887 http://blog.csdn.net/dslztx/article/details/48947097 http://www.zhihu.com/question/22881537 http://blog.csdn.net/shangboerds/article/details/7498317 http://blog.csdn.net/shuilan0066/article/details/7865715 http://www.zhihu.com/question/23374078 http://swiftlet.net/archives/category/char-encoding http://blog.csdn.net/shuilan0066/article/details/7839189 http://www.ibm.com/developerworks/cn/java/j-lo-chinesecoding/ http://www.freebuf.com/articles/others-articles/25623.html http://blog.csdn.net/qinysong/article/details/1179513 http://unicode-table.com/cn/]]></content>
      <categories>
        <category>encode</category>
      </categories>
      <tags>
        <tag>encode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ICMP Redirect Attack]]></title>
    <url>%2F2018%2F04%2F12%2FICMP-Redirect-Attack%2F</url>
    <content type="text"><![CDATA[原理分析ICMP协议的redirect,在某些特定的环境下,还是有些用处的。具体的可以参看:When Are ICMP Redirects SentExplanation of ICMP Redirect Behavior 由于ICMP redirect可以动态的更改host的路由,从安全角度考虑,允许accept ICMP redirect的信息话带来的弊大于利。因此在系统加固的手册中,往往都建议将icmp redirect丢弃掉。 我想知道的是,在系统默认的配置下。通过构造特定ICMP redirect的数据包,被攻击者是否真的会受到影响；以及需要满足什么样的条件? icmp redirect packet一个标准的icmp redirect packet 如下所示:0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Type | Code | Checksum |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Gateway Internet Address |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+| Internet Header + 64 bits of Original Data Datagram |+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+TYPE为5,表示为一个icmp redirect类数据；Code有4类: 0 = Redirect datagrams for the Network.1 = Redirect datagrams for the Host.2 = Redirect datagrams for the Type of Service and Network.3 = Redirect datagrams for the Type of Service and Host. 其中Code为0的这类,在microsoft网站的文档中显示已经被废除掉了；我通过测试发现,Code设置为0和1是没有什么区别。 icmp redirect processes一个正常的icmp redirect过程是这样的,host_A希望访问remote_A的tcp 123端口,当数据包发送到gateway_A,gateway_A发现到remote_A的路由应该走和host_A同网段的host_B,因此就会发 送一个icmp redirect信息,告诉你要访问remote_A的路由应该是走host_B,因此host_A就临时修改路由表,将访问remote_A的路由指向 host_B。 其实,操作系统设计人员,已经考虑到了可能会受到的攻击,因此当host_A收到icmp redirect数据时,会对该数据包进行验证,通过后才会修改自己的路由表。一下是我在freebsd6.2-7.2和linux center-os 5.2下测试的结果:freebsd： icmp redirect数据包的的源ip地址必须是主机的default gateway; remote_A必须和自己不是同一个网段;linux: icmp redirect数据包的的源ip地址必须是主机的default gateway; remote_A必须和自己不是同一个网段; 先前有发送访问remote_A的数据包，但是并不验证协议和端口号是否和icmp redirect回应的数据包相符。4.host_B是存活的——可以通过arp学到host_B的mac地址。 从 以上这些限制中,可以看出linux比freebsd在icmp redirect这块儿是要严格一些。但是依然可以通过发送伪造的icmp redirect数据包,恶意修改被攻击者的路由表,修改被攻击者和特定ip之间的网络路径;实现流量劫持或者DoS的目的。更重要的是经过验证,该攻击 是可以跨网段的。 攻击实例假设一台放在IDC内的服务器,操作系统为freebsd,ip地址为1.1.1.5。我们通过扫描,能够猜测到网关为1.1.1.1。这样我们可以从一台直接连接到互联网上的机器发起攻击(直接连接互联网的原因是为了避免SNAT)。使用SING伪造ICMP攻击数据包: ./sing -red -gw 1.1.1.4 -dest x.x.x.x -S 1.1.1.1 -x host -prot tcp -psrc 123 -pdst 123 1.1.1.5 这样,当freebsd接受到该icmp redirect数据包后,就会在路由表中添加一条到x.x.x.x的路由,该路由gw为1.1.1.4,可以通过netstat -rn查看。 Destination Gateway Flags Refs Use Netif Expire default 1.1.1.1 UGS 0 11164121 em1 x.x.x.x 1.1.1.4 UGHD3 0 0 em1 3600 ……过期时间为3600秒。如果1.1.1.4是不存在的ip或者没有转发功能,那么这台机器到x.x.x.x的网络将会中断。 如果针对linux的话,可能会有些限制。针对上个例子,就要求1.1.1.4这台机器是存活的同网段主机,不过这里机器应该不难找。 危害分析这 类攻击有一个很大的限制,就是一个icmp redirect只能影响受攻击者和单独一个ip地址之间的正常通信;无法造成受攻击者完全被DoS。但是在具体的应用环境中,可以对一些关键设备实施攻 击,从而造成比较大的影响;毕竟对攻击者来说,发送几个icmp数据包的成本还是比较低的。例如:针对DNS服务器,可以将从A-M的的几个root server的ip地址通过icmp redirect,那么应该会造成影响(当然也要看具体DNS服务器的服务类型)。 修复建议找到system内核参数配置文件/etc/sysctl.conf： 修改： ################################################################### # Additional settings - these settings can improve the network # security of the host and prevent against some network attacks # including spoofing attacks and man in the middle attacks through # redirection. Some network environments, however, require that these # settings are disabled so review and enable them as needed. # # Do not accept ICMP redirects (prevent MITM attacks) #net.ipv4.conf.all.accept_redirects = 0 #net.ipv6.conf.all.accept_redirects = 0 # _or_ # Accept ICMP redirects only for gateways listed in our default # gateway list (enabled by default) # net.ipv4.conf.all.secure_redirects = 1 # # Do not send ICMP redirects (we are not a router) #net.ipv4.conf.all.send_redirects = 0` 为 ################################################################### # Additional settings - these settings can improve the network # security of the host and prevent against some network attacks # including spoofing attacks and man in the middle attacks through # redirection. Some network environments, however, require that these # settings are disabled so review and enable them as needed. # # Do not accept ICMP redirects (prevent MITM attacks) net.ipv4.conf.all.accept_redirects = 0 net.ipv6.conf.all.accept_redirects = 0 # _or_ # Accept ICMP redirects only for gateways listed in our default # gateway list (enabled by default) # net.ipv4.conf.all.secure_redirects = 1 # # Do not send ICMP redirects (we are not a router) net.ipv4.conf.all.send_redirects = 0 然后应用内核参数配置 $ sudo sysctl -p 全部相关参数： net.ipv4.conf.all.accept_redirects = 0 net.ipv6.conf.all.accept_redirects = 0 net.ipv4.conf.all.send_redirects = 0 net.ipv4.conf.default.accept_redirects = 0 net.ipv6.conf.default.accept_redirects = 0 net.ipv4.conf.default.send_redirects = 0 referencehttp://www.cymru.com/gillsr/documents/icmp-redirects-are-bad.pdfhttp://sourceforge.net/projects/sing/http://tools.ietf.org/html/rfc792]]></content>
      <categories>
        <category>security</category>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>route</tag>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux look up route]]></title>
    <url>%2F2018%2F04%2F11%2FLinux-look-for-route-table%2F</url>
    <content type="text"><![CDATA[本文介绍几种获取linux当前系统路由表的命令 route[root@localhost ~]# route Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface default 192.168.150.1 0.0.0.0 UG 1024 0 0 eno16780032 192.168.150.0 0.0.0.0 255.255.255.0 U 0 0 0 eno16780032 ip rule[root@localhost ~]# ip rule 0: from all lookup local 32766: from all lookup main 32767: from all lookup default ip route list table[root@localhost ~]# ip route list table all default via 192.168.150.1 dev eno16780032 proto static metric 1024 192.168.150.0/24 dev eno16780032 proto kernel scope link src 192.168.150.151 broadcast 127.0.0.0 dev lo table local proto kernel scope link src 127.0.0.1 local 127.0.0.0/8 dev lo table local proto kernel scope host src 127.0.0.1 local 127.0.0.1 dev lo table local proto kernel scope host src 127.0.0.1 broadcast 127.255.255.255 dev lo table local proto kernel scope link src 127.0.0.1 broadcast 192.168.150.0 dev eno16780032 table local proto kernel scope link src 192.168.150.151 local 192.168.150.151 dev eno16780032 table local proto kernel scope host src 192.168.150.151 broadcast 192.168.150.255 dev eno16780032 table local proto kernel scope link src 192.168.150.151 local ::1 dev lo proto kernel metric 256 unreachable ::/96 dev lo metric 1024 error -101 unreachable ::ffff:0.0.0.0/96 dev lo metric 1024 error -101 unreachable 2002:a00::/24 dev lo metric 1024 error -101 unreachable 2002:7f00::/24 dev lo metric 1024 error -101 unreachable 2002:a9fe::/32 dev lo metric 1024 error -101 unreachable 2002:ac10::/28 dev lo metric 1024 error -101 unreachable 2002:c0a8::/32 dev lo metric 1024 error -101 unreachable 2002:e000::/19 dev lo metric 1024 error -101 unreachable 3ffe:ffff::/32 dev lo metric 1024 error -101 fe80::/64 dev eno16780032 proto kernel metric 256 unreachable default dev lo table unspec proto kernel metric 4294967295 error -101 local ::1 dev lo table local proto none metric 0 local fe80::20c:29ff:fe9f:7ea6 dev lo table local proto none metric 0 ff00::/8 dev eno16780032 table local metric 256 unreachable default dev lo table unspec proto kernel metric 4294967295 error -101 ip route get[root@localhost ~]# ip route get 114.114.114.114 114.114.114.114 via 192.168.150.1 dev eno16780032 src 192.168.150.151]]></content>
      <categories>
        <category>linux</category>
        <category>command</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>route</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web缓存之：基础知识]]></title>
    <url>%2F2018%2F04%2F10%2Fweb-cache-basic-kb%2F</url>
    <content type="text"><![CDATA[Caching is a technique that stores a copy of a given resource and serves it back when requested. When a web cache has a requested resource in its store, it intercepts the request and returns its copy instead of re-downloading from the originating server. Web缓存是指一个Web资源（如html页面，图片，js，数据等）存在于Web服务器和客户端（浏览器）之间的副本。缓存会根据进来的请求保存输出内容的副本；当下一个请求来到的时候，如果是相同的URL，缓存会根据缓存机制决定是直接使用副本响应访问请求，还是向源服务器再次发送请求。 Advantagement of Web Cache Improving the performance by reusing previously fetched resources. Reducing latency and network traffic. Web sites become more responsive. Different kinds of cachesCache从作用和部署位置来说有好几种类型：gateway caches, CDN, reverse proxy caches and load balancers 。这些有利于Web Server提高可用性，提升性能和横向扩展* Reverse Proxy Cache代理服务器是浏览器和源服务器之间的中间服务器，浏览器先向这个中间服务器发起Web请求，经过处理后（比如权限验证，缓存匹配等），再将请求转发到源服务器。代理服务器缓存的运作原理跟浏览器的运作原理差不多，只是规模更大。可以把它理解为一个共享缓存，不只为一个用户服务，一般为大量用户提供服务，因此在减少相应时间和带宽使用方面很有效，同一个副本会被重用多次。常见代理服务器缓存解决方案有Squid等，这里不再详述。 CDNCDN（Content delivery networks）缓存，也叫网关缓存、反向代理缓存。CDN缓存一般是由网站管理员自己部署，为了让他们的网站更容易扩展并获得更好的性能。浏览器先向CDN网关发起Web请求，网关服务器后面对应着一台或多台负载均衡源服务器，会根据它们的负载请求，动态将请求转发到合适的源服务器上。虽然这种架构负载均衡源服务器之间的缓存没法共享，但却拥有更好的处扩展性。从浏览器角度来看，整个CDN就是一个源服务器，从这个层面来说，本文讨论浏览器和服务器之间的缓存机制，在这种架构下同样适用。 Web应用层缓存应用层缓存指的是从代码层面上，通过代码逻辑和缓存策略，实现对数据，页面，图片等资源的缓存，可以根据实际情况选择将数据存在文件系统或者内存中，减少数据库查询或者读写瓶颈，提高响应效率。 浏览器端缓存浏览器缓存根据一套与服务器约定的规则进行工作，在同一个会话过程中会检查一次并确定缓存的副本足够新。如果你浏览过程中，比如前进或后退，访问到同一个图片，这些图片可以从浏览器缓存中调出而即时显现。 SQL CacheWeb应用，特别是SNS类型的应用，往往关系比较复杂，数据库表繁多，如果频繁进行数据库查询，很容易导致数据库不堪重荷。为了提供查询的性能，会将查询后的数据放到内存中进行缓存，下次查询时，直接从内存缓存直接返回，提供响应效率。比如常用的缓存方案有memcached等。 Controlling cachingThe header: Cache-control The Cache-Control HTTP/1.1 general-header field is used to specify directives for caching mechanisms in both requests and responses. Use this header to define your caching policies with the variety of directives it provides. HTTP1.1版本才添加的缓存控制机制，其在请求报文或响应报文首部添加一个cache-control的首部，用于定义资源的缓存最大时长，是相对于响应报文首部中的date首部定义的时间。一般响应报文首部会同时有Expires首部和Cache-control首部 No cache storage at all The cache should not store anything about the client request or server response. A request is sent to the server and a full response is downloaded each and every time.完全不缓存 Cache-Control: no-store Cache-Control: no-cache, no-store, must-revalidate No caching A cache will send the request to the origin server for validation before releasing a cached copy.会缓存，但是每次请求都会确认 Cache-Control: no-cache Private and public cachesPrivate Cache 只能被单个用户使用。Public Cache可以被多个用户复用。 Cache-Control: private Cache-Control: public ExpirationThe most important directive here is “max-age=&lt;seconds>“ which is the maximum amount of time a resource will be considered fresh. Contrary to Expires, this directive is relative to the time of the request. For the files in the application that will not change, you can usually add aggressive caching. This includes static files such as images, CSS files and JavaScript files, for example. For more details, see also the Freshness section below. Cache-Control: max-age=31536000 ValidationWhen using the “must-revalidate” directive, the cache must verify the status of the stale resources before using it and expired ones should not be used. For more details, see the Validation section below. Cache-Control: must-revalidate 对Cache-Control头不同的值归纳 cache-request-directive=no-cache 不接受缓存响应 no-store 不缓存在本地 max-age 缓存最大有效时长 min-fresh cache-response-directive=public private no-cache no-store must-revalidate max-age // no-cache：可缓存，但用户每次请求都需要先到上游服务器做缓存检验 The Pragma headerPragma 是一个 HTTP/1.0 header，在HTTP/1.1中并没有定义它为一个HTTP response头，因为我们已经有了 Cache-Control header。这个只是为了兼容HTTP/1.0的客户端。 &lt;META HTTP-EQUIV=&quot;Pragma&quot; CONTENT=&quot;no-cache&quot;&gt; 上述代码的作用是告诉浏览器当前页面不被缓存，每次访问都需要去服务器拉取。使用上很简单，但只有部分浏览器可以支持，而且所有缓存代理服务器都不支持，因为代理不解析HTML内容本身。 可以通过这个页面测试你的浏览器是否支持：Pragma No-Cache Test Varying responsesVary response header从在Client上多个不同的cache副本筛选合适的版本 The Vary HTTP response header determines how to match future request headers to decide whether a cached response can be used rather than requesting a fresh one from the origin server. When a cache receives a request that can be satisfied by a cached response that has a Vary header field, it must not use that cached response unless all header fields as nominated by the Vary header match in both the original (cached) request and the new request. The Vary header leads cache to use more HTTP headers as key for the cache. This can be useful for serving content dynamically, for example. When using the Vary: User-Agent header, caching servers should consider the user agent when deciding whether to serve the page from cache. If you are serving different content to mobile users, it can help you to avoid that a cache may mistakenly serve a desktop version of your site to your mobile users. In addition, it can help Google and other search engines to discover the mobile version of a page, and might also tell them that no Cloaking is intended. Because the User-Agent header value is different (“varies”) for mobile and desktop clients, caches will not be used to serve mobile content mistakenly to desktop users or vice versa. Freshness新鲜度:资源被存储到缓存后，必须要有回收机制（cache eviction）以释放占用的存储空间；另外因为Web资源可能会不停地更新，缓存也需要过期机制（expiration time），也就是缓存副本有效期。 Cache eviction 缓存项过期：缓存资源往往会被设置有效时长，过期自动清理或失效 缓存空间用尽：缓存空间用尽时，会根据LRU（最近最小使用）算法清理缓存 清理策略设置过长过短都不好，过长数据容易陈旧，过短起不到缓存效果 LifetimeShow how a proxy cache acts when a doc is not cache, in the cache and fresh, in the cache and stale. Here is an example of this process with a shared cache proxy: flow as follows: 是否过期（expeired）通过”Cache-control: max-age=N“ header 或者 Expires header 判断。max-age根据Dateheader和N判读是否expired；Expires则会直接记录expiration time. Etag header记录的是resource文件的MD5值，通过MD5判断server上该文件是否有改动。 Last-Modified记录resource文件最后update时间，精确到秒。 Cache-Control与ExpiresCache-Control与Expires的作用一致，都是指明当前资源的有效期，控制浏览器是否直接从浏览器缓存取数据还是重新发请求到服务器取数据。只不过Cache-Control的选择更多，设置更细致，如果同时设置的话，其优先级高于Expires。 Last-Modified/ETag与Cache-Control/Expires配置Last-Modified/ETag的情况下，浏览器再次访问统一URI的资源，还是会发送请求到服务器询问文件是否已经修改，如果没有，服务器会只发送一个304回给浏览器，告诉浏览器直接从自己本地的缓存取数据；如果修改过那就整个数据重新发给浏览器； Cache-Control/Expires则不同，如果检测到本地的缓存还是有效的时间范围内，浏览器直接使用本地副本，不会发送任何请求。两者一起使用时，Cache-Control/Expires的优先级要高于Last-Modified/ETag。即当本地副本根据Cache-Control/Expires发现还在有效期内时，则不会再次发送请求去服务器询问修改时间（Last-Modified）或实体标识（Etag）了。 一般情况下，使用Cache-Control/Expires会配合Last-Modified/ETag一起使用，因为即使服务器设置缓存时间, 当用户点击“刷新”按钮时，浏览器会忽略缓存继续向服务器发送请求，这时Last-Modified/ETag将能够很好利用304，从而减少响应开销。 Last-Modified与ETag你可能会觉得使用Last-Modified已经足以让浏览器知道本地的缓存副本是否足够新，为什么还需要Etag（实体标识）呢？HTTP1.1中Etag的出现主要是为了解决几个Last-Modified比较难解决的问题： Last-Modified标注的最后修改只能精确到秒级，如果某些文件在1秒钟以内，被修改多次的话，它将不能准确标注文件的新鲜度,属于弱检验（weak validator） 如果某些文件会被定期生成，当有时内容并没有任何变化，但Last-Modified却改变了，导致文件没法使用缓存 有可能存在服务器没有准确获取文件修改时间，或者与代理服务器时间不一致等情形 Etag是服务器自动生成或者由开发者生成的对应资源在服务器端的唯一标识符，能够更加准确的控制缓存。属于强检验（strong validator） Last-Modified与ETag是可以一起使用的，服务器会优先验证ETag，一致的情况下，才会继续比对Last-Modified，最后才决定是否返回304。 Etag的服务器生成规则和强弱Etag的相关内容可以参考《HTTP Header definition》， Reused resources并非所有的数据被缓存或需要缓存，缓存是为了解决20%数据被80%的人频繁访问的问题而生。所有我们必须要考虑缓存的复用率。 The data we cache数据如希望被缓存往往具备变化缓慢的特征。被缓存的数据往往具备如下特性： 时间局部性缓存的数据往往被打有时间缀，具有定期失效的特征，过期后会从源服务器检验请求验证是否需要重新拉取数据。某数据被访问后，该数据往往会再次在短时间内被访问到。 空间局部性被访问数据的周边数据被访问的概率会比其它常规数据访问大很多，所以这些访问数据和其它周边有可能被访问的数据通过某种方式集中在一起，以提高数据的被访问速度，减少数据查找时长。完成这类功能的工具往往称为Cache。 热（区）数据所谓热（区）数据就是指经常被访问到的数据，这类数据被缓存最有价值，缓存命中率高 The data we do not cache用户账号密码信息等数据，该类数据不仅不应该被缓存，反而要被着重保护，这些年发生的撞库，密码破解等恶性事件，往往都是因为用户个人不当心或企业安全意味不足，导致用户敏感信息流失。 Cache hit缓存命中率=hit/(hit+mixx)hit表示缓存被命中，miss表示没有命中，也就是缓存项中没有对应的资源文档命中率：从文档命中的个数进行衡量字节命中率：从内容命中的大小(字节)进行衡量 This is very important when web sites have CSS stylesheets or JS scripts that have mutual dependencies, i.e., they depend on each other because they refer to the same HTML elements. Can NOT CachesHTTP信息头中包含Cache-Control:no-cache，pragma:no-cache，或Cache-Control:max-age=0等告诉浏览器不用缓存的请求需要根据Cookie，认证信息等决定输入内容的动态请求是不能被缓存的经过HTTPS安全加密的请求（有人也经过测试发现，ie其实在头部加入Cache-Control：max-age信息，firefox在头部加入Cache-Control:Public之后，能够对HTTPS的资源进行缓存，参考《HTTPS的七个误解》）POST请求无法被缓存HTTP响应头中不包含Last-Modified/Etag，也不包含Cache-Control/Expires的请求无法被缓存]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>web</tag>
        <tag>cache</tag>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo Learning]]></title>
    <url>%2F2018%2F04%2F05%2FHexo-Learning%2F</url>
    <content type="text"><![CDATA[作为搭建个人blog最为重要的组件，Hexo可以说是最核心的部分，不仅是因为它提供了基本的框架，而且还有丰富的扩展包，自定义主题格式等丰富功能，最重要的是作为新手来说简洁易懂。 what is Hexo?Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 安装 Hexo安装前提在安装前，已安装下列应用程序：Node.jsGit 所有必备的应用程序安装完成后，即可使用 npm 安装 Hexo。 $ npm install -g hexo-cli 建站（本地）安装 Hexo 完成后，请执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。 $ hexo init &lt;folder&gt; $ cd &lt;folder&gt; $ npm install 新建完成后，指定文件夹的目录如下： .├── _config.yml├── package.json├── scaffolds├── source| ├── _drafts| └── _posts└── themes 文件和目录_config.yml – 网站的 配置 信息，您可以在此配置大部分的参数。package.json – 应用程序的信息。EJS, Stylus 和 Markdown renderer 已默认安装，您可以自由移除。 { &quot;name&quot;: &quot;hexo-site&quot;, &quot;version&quot;: &quot;0.0.0&quot;, &quot;private&quot;: true, &quot;hexo&quot;: { &quot;version&quot;: &quot;&quot; }, &quot;dependencies&quot;: { &quot;hexo&quot;: &quot;^3.0.0&quot;, &quot;hexo-generator-archive&quot;: &quot;^0.1.0&quot;, &quot;hexo-generator-category&quot;: &quot;^0.1.0&quot;, &quot;hexo-generator-index&quot;: &quot;^0.1.0&quot;, &quot;hexo-generator-tag&quot;: &quot;^0.1.0&quot;, &quot;hexo-renderer-ejs&quot;: &quot;^0.1.0&quot;, &quot;hexo-renderer-stylus&quot;: &quot;^0.2.0&quot;, &quot;hexo-renderer-marked&quot;: &quot;^0.2.4&quot;, &quot;hexo-server&quot;: &quot;^0.1.2&quot; } } scaffolds – 模版 文件夹。当您新建文章时，Hexo 会根据 scaffold 来建立文件。Hexo的模板是指在新建的markdown文件中默认填充的内容。例如，如果您修改scaffold/post.md中的Front-matter内容，那么每次新建一篇文章时都会包含这个修改。 source – 资源文件夹是存放用户资源的地方。除 _posts 文件夹之外，开头命名为 _ (下划线)的文件 / 文件夹和隐藏的文件将会被忽略。Markdown 和 HTML 文件会被解析并放到 public 文件夹，而其他文件会被拷贝过去。themes – 主题 文件夹。Hexo 会根据主题来生成静态页面。 Tag PluginsQuota {% blockquote [author[, source]] [link] [source_link_title] %} content {% endblockquote %} Code {% codeblock [title] [lang:language] [url] [link text] %} code snippet {% endcodeblock %} Image {% img [class names] /path/to/image [width] [height] [title text [alt text]] %} path start with the public folder Hexo extension packagesdeploy to git website $ npm install hexo-deployer-git --save $ hexo d -g enable search feature $ npm install hexo-generator-search --save enable acticle wordcount $ npm install hexo-wordcount --save enable generate tag feature and pages $ npm install hexo-generator-tag --save enable website search feature $ npm install hexo-generator-searchdb --save Hexo documentation想要学习更详细的Hexo，传送门]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git Learning]]></title>
    <url>%2F2018%2F04%2F05%2FGit-Learning%2F</url>
    <content type="text"><![CDATA[reopsitory库，最基本的概念,需要做版本控制的目录或文件的集合都会保存在一个Repo中，通过Git命令可以看到每一个之前修改过的版本。 local Repo与Remote Repo可以建立映射关系local repository &lt;&lt;====&gt;&gt; remote repository 目录c:/user/admin/git/下文件加入到Repo后后，local file可以与remote file可以形成相互备份关系。local directory(c:/user/admin/git/*) &lt;&lt;====&gt;&gt; https://github.com/username/repository Branch分支就是科幻电影里面的平行宇宙，当你正在电脑前努力学习Git的时候，另一个你正在另一个平行宇宙里努力学习SVN。 如果两个平行宇宙互不干扰，那对现在的你也没啥影响。不过，在某个时间点，两个平行宇宙合并了，结果，你既学会了Git又学会了SVN！ Github Useful Command初始化 repoadmin@admin-PC MINGW64 ~ $ mkdir git $ cd git $ pwd /c/Users/admin/git $ git init 添加到版本控制$ git add README.txt $ git commit -m &quot;discript what have done in files&quot; //提交确认修改` 为什么Git添加文件需要add，commit一共两步呢？因为commit可以一次提交很多文件，所以你可以多次add不同的文件 查看git状态$ git status 查看修改的内容$ git diff file 查看commit log$ git log 很明显这查看表示历史修改版本记录，最主要是看commit id。 reset到指定的版本$ git reset --hard HEAD^ 表示回退， 至于HEAD主要是与commit id映射，HEAD^表示上一个版本，HEAD~100，表示上100版本！这个鬼记得往上100个版本做了什么… 当然也可以直接写commit id， 更深的理解，commit id保存所有历史版本，HEAD只是一个指针。 reform log$ git reflog 这个做什么呢，记录commit id - HEAD - actions的映射关系。方便吃后悔药。 $ git reflog a944eee (HEAD -&gt; master) HEAD@{0}: commit: vertion 2: added time. be90283 HEAD@{1}: commit (initial): edit the readme file checkout$ git checkout -- file 只要没有把版本推送到远程库，一切误操作都可以清除。包括是git reset HEAD file。 ####remove file $ git rm file 删除文件，误删除怎么办，上一步刚说过，checkout remote repositoryGit的天敌是SVN，不过SVN已经在沙滩上了，Git是怎么做到的？ K.O技能：remote repository。 Now，请注册一个Github账号—完全免费共享的remote repository。如果有秘密项目，那么可以自己搭建一个git server。 $ git remote add origin git@github.com:username/repository //添加remote git库 $ git remote add origin https://github.com/username/repositor //另一种方式添加remote repo push$ git push -u origin master //将本地库推送到remote clone$ git clone git@github.com:username/repository //同步remote库到本地，通过SSH协议 $ git clone https://github.com/username/repository //通过https协议 swich branch$ git checkout -b branchname 创建并切换分支。相当于 $ git branch branchname $ git checkout branchname check branch$ git branch merge branch$ git merge branchname (--no-ff) 合并branch，no off 表示关闭fast forward模式，将命令中的branch merge到当前workaround的branch。 delete branch$ git branch -d branchname Git learning review廖雪峰最简单易懂Git学习Git Learning]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tech Blog最佳实践]]></title>
    <url>%2F2018%2F03%2F30%2Ftech-blog%2F</url>
    <content type="text"><![CDATA[本文主要说明构建个人博客需要的所有工具和条件，以及每一个组件在构建blog的说明和作用，并不是完整的操作手册。在搭建博客前通过阅读本文，完整的明白各个组件承担的响应的角色，当遇到问题时可以清楚地确定问题可能发生的原因。推荐完整看完本文后再进入各个组件深入学习。本文阅读时间1小时。 ToolsGit + Github Pages + Node.js + Hexo + NexT Theme knowledge Base Git – 熟悉Git的工作原理和怎样使用Git。 推荐时间：2天 Github – 练习注册一个 账号github , 创建并练习使用repository，搭建Github pages。推荐时间： 1天 Hexo – 安装Hexo, 设置基本的Hexo配置练习。推荐时间： 1天 NexT Theme –从Hexo 默认Theme切换到NexT后，练习自定义主题主要的元素。推荐时间： 0.5天 Markdown – 学会使用Markdown的语法编辑文档，通过Markdown编辑器练习使用各种标签。推荐时间：0.5天 GitGit是目前世界上最先进的分布式版本控制系统（没有之一）。那什么是版本控制系统？ 在编辑文档时，如果有一个软件，不但能自动帮我记录每次文件的改动，还可以让同事协作编辑，这样就不用自己管理一堆类似的文件了，也不需要把文件传来传去。如果想查看某次改动，只需要在软件里瞄一眼就可以，岂不是很方便？ 这样，你就结束了手动管理多个“版本”的史前时代，进入到版本控制的20世纪，这个软件就是Git。 还不明白，可以进入廖雪峰老师的文档继续深入学习：Git introduction Git下载地址：Git Download Node.jsNode.js并不需要我们了解怎样使用它。我们只需要知道下面的Hexo能够正常工作需要依赖Node.js。所以只需要知道如何安装： 下载并安装nvm.（什么是nvm？不需要知道，只需要知道他可以方便安装node.js） Download nvm $ curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.33.8/install.sh install nvm $ cd .nvm/ $ ./install.sh set bash profile $ export NVM_DIR=&quot;$HOME/.nvm&quot; $ [ -s &quot;$NVM_DIR/nvm.sh&quot; ] &amp;&amp; \. &quot;$NVM_DIR/nvm.sh&quot; install Node.js $ nvm install stable GitHub PageGithub做为Git的云端版本库，可以放任何人随时随地边编辑和发布文档，而且完全开源免费。Github Page作为Github的一个功能，只需要将站点文件上传到Github上，你可以拥有自己的免费Blog平台，不需要托管主机，不需要域名。 account: yourusername通过ssh方式连接Github： git@github.com:_yourusername_/ 通过http方式连接Github： https://github.com/_yourusername_/ $ git config --global user.name &quot;Your Name&quot; $ git config --global user.email &quot;email@example.com&quot; HexoHexo 是高效的静态站点生成框架，她基于 Node.js。 通过 Hexo 你可以轻松地使用 Markdown 编写文章，除了 Markdown 本身的语法之外，还可以使用 Hexo 提供的 标签插件 来快速的插入特定形式的内容。什么意思呢？ 我们知道静网页文件都是.html文件，需要很多标签对格式进行控制。如果我们有Hexo后，我们可以将可读性很高的文本档使用Markdown的语法通过Hexo转换成.html文件，并且生成完整的完整框架。我们只需要编辑文本文件，通hexo生成网站的框架和内容，并且部署生成自己的网站。 Install hexo $npm install hexo-cli -g set up hexo $hexo init blog $cd blog $npm install $hexo server NexT如果说Hexo为一个人的躯体，那么NexT就是这个躯体的衣服，让Hexo变得更美，这就是NexT。 在 Hexo 中有两份主要的配置文件，其名称都是 _config.yml。 其中，一份位于站点根目录下，主要包含 Hexo 本身的配置；另一份位于主题目录下，这份配置由主题作者提供，主要用于配置主题相关的选项。 为了描述方便，在以下说明中，将前者称为 站点配置文件， 后者称为 主题配置文件。 安装 NexTHexo 安装主题的方式非常简单，只需要将主题文件拷贝至站点目录的 themes 目录下， 然后修改下配置文件即可。具体到 NexT 来说，安装步骤如下。 下载主题 $ cd your-hexo-site $ git clone https://github.com/iissnan/hexo-theme-next themes/next 启用主题 #编辑系统配置文件_config.yml,找到Theme设置并将值改成next theme: next 验证主题 $hexo s --debug INFO Hexo is running at http://0.0.0.0:4000/. Press Ctrl+C to stop. MarkdownMarkdown 是一个 Web 上使用的文本到HTML的转换工具，可以通过简单、易读易写的文本格式生成结构化的HTML文档。目前 github、Stackoverflow 等网站均支持这种格式.Markdown ENDING http://zhaoweihao.me/2017/04/29/Hexo-Github-pages-%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B1%9E%E4%BA%8E%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/ https://www.cnblogs.com/fengxiongZz/p/7707219.html]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>git</tag>
        <tag>hexo</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown Quick Guide]]></title>
    <url>%2F2018%2F03%2F29%2Fmarkdown%2F</url>
    <content type="text"><![CDATA[本文主要介绍Markdown的基本使用方法，基本不用了解HTML的语法。按照本文的说明编辑文本后，只要通过Markdown编辑器，就能生成一个html文件。本文阅读时间大约1-2个小时。 概览宗旨Markdown 的目标是实现「易读易写」。 兼容 HTMLMarkdown 语法的目标是：成为一种适用于网络的书写语言。 特殊字符自动转换在 HTML 文件中，有两个字符需要特殊处理： &lt; 和 &amp; 。 &lt; 符号用于起始标签，&amp; 符号则用于标记 HTML 实体，如果你只是想要显示这些字符的原型，你必须要使用实体的形式，像是 &lt; 和 &amp;。 区块元素段落和换行在插入处先按入两个以上的空格然后回车 标题在行首插入 1 到 6 个 #，对应到标题 1 到 6 阶，例如： # 这是 H1 ## 这是 H2 ###### 这是 H6 区块引用blockquotes用 &gt; 的引用方式，例如： This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet,consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus.Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus. 区块引用可以嵌套，例如： This is nested blockquote. Back to the first level 列表序列表使用星号、加号或是减号作为列表标记： * Red * Green * Blue 有序列表则使用数字接着一个英文句点： 1. Bird 2. McHale 3. Parish 列表项目标记通常是放在最左边，但是其实也可以缩进，最多 3 个空格，项目标记后面则一定要接着至少一个空格或制表符。 列表项目可以包含多个段落，每个项目下的段落都必须缩进 4 个空格或是 1 个制表符： 如果要放代码区块的话，该区块就需要缩进两次，也就是 8 个空格或是 2 个制表符： 在行首出现数字-句点-空白: 1986. What a great season. 代码区块要在 Markdown 中建立代码区块很简单，只要简单地缩进 4 个空格或是 1 个制表符就可以，例如，下面的输入： 这是一个普通段落： 这是一个代码区块。 一个代码区块会一直持续到没有缩进的那一行（或是文件结尾）。 分隔线你可以在一行中用三个以上的星号、减号、底线来建立一个分隔线 * * * *** ***** - - - --------------------------------------- 区段元素链接行内式的链接，只要在方块括号后面紧接着圆括号并插入网址链接即可: This is [an example](http://example.com/ &quot;Title&quot;) inline link. [This link](http://example.net/) has no title attribute. See my [About](/about/) page for details. 参考式的链接是在链接文字的括号后面再接上另一个方括号，而在第二个方括号里面要填入用以辨识链接的标记： This is [an example][id] reference-style link. 链接内容定义的形式为： * 方括号（前面可以选择性地加上至多三个空格来缩进），里面输入链接文字 * 接着一个冒号 * 接着一个以上的空格或制表符 * 接着链接的网址 * 选择性地接着 title 内容，可以用单引号、双引号或是括弧包着 下面是一个参考式链接的范例： I get 10 times more traffic from [Google] [1] than from [Yahoo] [2] or [MSN] [3]. [1]: http://google.com/ &quot;Google&quot; [2]: http://search.yahoo.com/ &quot;Yahoo Search&quot; [3]: http://search.msn.com/ &quot;MSN Search&quot; 强调Markdown 使用星号（*）和底线（_）作为标记强调字词的符号，被 * 或 _ 包围的字词会被转成用 &lt;em> 标签包围，用两个 * 或 _ 包起来的话，则会被转成 &lt;strong>，例如： *single asterisks* single asterisks _single underscores_ single underscores **double asterisks** double asterisks __double underscores__ double underscores 代码如果要标记一小段行内代码，你可以用反引号把它包起来（`），例如： Use the `printf()` function. 如果要在代码区段内插入反引号，你可以用多个反引号来开启和结束代码区段： 图片Markdown 使用一种和链接很相似的语法来标记图片，同样也允许两种样式： 行内式和参考式。行内式的图片语法看起来像是： ![Alt text](/path/to/img.jpg) ![Alt text](/path/to/img.jpg &quot;Optional title&quot;) 参考式的图片语法则长得像这样： ![Alt text][id] [id]: url/to/image &quot;Optional title attribute&quot; 其它反斜杠利用反斜杠来插入一些在语法中有其它意义的符号Markdown 支持以下这些符号前面加上反斜杠来帮助插入普通的符号： \ 反斜线 ` 反引号 * 星号 _ 底线 {} 花括号 [] 方括号 () 括弧 # 井字号 + 加号 - 减号 . 英文句点 ! 惊叹号 自动链接只要是用方括号包起来， Markdown 就会自动把它转成链接，一般网址的链接文字就和链接地址一样，例如： &lt;http://example.com/&gt; Markdown 免费编辑器Windows 平台 MarkdownPad MarkPad Linux 平台 ReText Mac 平台 Mou 在线编辑器 Markable.in Dillinger.io 浏览器插件 MaDe (Chrome) 高级应用(Sublime Text 2 + MarkdownEditing 教程) Sublime Text 2 MarkdownEditing 教程 感谢感谢: http://daringfireball.net/projects/markdown/ 原文：http://www.markdown.cn/#overview]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>HTML</tag>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[post picture]]></title>
    <url>%2F2018%2F03%2F27%2Fpost-picture%2F</url>
    <content type="text"><![CDATA[Totoro content]]></content>
      <categories>
        <category>film</category>
      </categories>
      <tags>
        <tag>film</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[boyhood]]></title>
    <url>%2F2018%2F03%2F15%2Fboyhood%2F</url>
    <content type="text"><![CDATA[教程史上最浅显易懂的Git教程！ LiaoxuefengGit教程Code#!&#x2F;bin&#x2F;bash for (i=0,i++,i&lt;a) do i=i++; echo $i; done Link互联网工程任务组（IETF）已正式批准TLS 1.3作为传输层安全（TLS）协议的下一个主要版本，IETF组织是专门批准互联网标准和协议的组织。]]></content>
      <categories>
        <category>film</category>
      </categories>
      <tags>
        <tag>film</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《朝花夕拾》]]></title>
    <url>%2F2018%2F03%2F15%2Fhello-world%2F</url>
    <content type="text"><![CDATA[我常想在纷扰中寻出一点闲静来，然而委实不容易。目前是这么离奇，心里是这么芜杂。一个人做到只剩了回忆的时候，生涯大概总要算是无聊了罢，但有时竟会连回忆也没有。 前天，已将《野草》编定了；这回便轮到陆续载在《莽原》上的《旧事重提》，我还替他改了一个名称：《朝花夕拾》。带露折花，色香自然要好得多，但是我不能够。便是现在心目中的离奇和芜杂，我也还不能使他即刻幻化，转成离奇和芜杂的文章。或者，他日仰看流云时，会在我的眼前一闪烁罢。 我有一时，曾经屡次忆起儿时在故乡所吃的蔬果：菱角、罗汉豆、茭白、香瓜。凡这些，都是极其鲜美可口的；都曾是使我思乡的蛊惑。后来，我在久别之后尝到了，也不过如此；惟独在记忆上，还有旧来的意味留存。他们也许要哄骗我一生，使我时时反顾。 ——《朝花夕拾》小引正如鲁迅先生给文集取名《朝花夕拾》一样，当我第一次感觉到每天忙于各种凌杂的琐碎，无暇去思考和记录做过的一些工作，而当再次拿起这些工作时，记忆是那么的空白，没有一点线索可以现成的找寻。想想在这些年的工作中，有做过不少研究和探索，零散的记录在不同的地方，或是在纸质的笔记本上，在不同的文件夹中，在在线软件文档中，有些干脆没有记录，只是在大脑中保存一点记忆。取名《朝花夕拾》这个寓意很好，这些年来工作中，重新整理那些有意义的资料文档，即可归纳总结多年来工作的成绩，也保存有价值的历史资料或记忆。 回忆，我发现，可能是不可靠的东西，尝尝被你回忆时的环境所大大的扭曲。 ——《远山淡影》石黑一雄 当石黑一雄获得诺贝尔文学奖时，当我我看《远山淡影》这本书时，没忍住买了一本但是没怎么看懂。后来一次去一家书店阅读时，看到上面这段书评，心中瞬间被这就句话触动了。回想阅读这本书时的情节突然就想通了。 记忆，可不就是这样吗？曾经很熟悉的知识内容，在时间的冲淡下，常常只有一个模糊印象，更糟糕的是将几个不相关的片段串在一起。对于技术这个来说，太要糟糕了，当再去想用过的东西还需要不停的调试和排错，这对效率来说是巨大的损失，对精力是巨大的折磨。我们太需要这种实实在在东西将我们印象的东西记录下来。 Without you,who would I admire all the beautiful things with.“没有你 良辰美景可与何人说。” ——《天使爱美丽》台词 最后，我要说的是，对于关于Share这件事，我想这也是Github的核心精神，将自己的贡献上传到公共的平台上，不仅是一个免费展示自己的平台，而且让那些需要的人可以浏览和下载。在Share中获得快乐，同时又可以帮助他人，这或许也是一种自我实现。 这大概就是我记录博客的初衷吧。]]></content>
  </entry>
</search>
